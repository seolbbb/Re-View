{
  "schema_version": 1,
  "items": [
    {
      "timestamp_ms": 0,
      "extracted_text": "[ML for RecSys]\n**변분추론 II**\n\n---\n\n송경우\n연세대학교 응용통계학과, 통계데이터사이언스학과\n\nWARNING: 본 교육 콘텐츠의 저작재산권은 제단법인 네이버커넥트에 귀속됩니다. 본 콘텐츠를 어떠한 경로로든 외부로 유출 및 수정하는 행위를 엄격히 금합니다. 다만, 비영리적 교육 및 연구활동에 한정되어 사용할 수 있으나 제단의 허락을 받아야 합니다. 이를 위반하는 경우, 관련 법률에 따라 책임을 질 수 있습니다.\n\nboostcamp aitech\n© NAVER Connect Foundation\n\n- 이미지 상단에는 `[ML for RecSys]`와 `변분추론 II`라는 제목이 표시되어 있으며, 강의 제목과 주제를 나타낸다.\n- 강사 정보는 송경우 교수로, 연세대학교 응용통계학과 및 통계데이터사이언스학과 소속임.\n- 하단에는 저작권 경고 문구와 `boostcamp aitech`, `NAVER Connect Foundation` 로고가 포함되어 있다."
    },
    {
      "timestamp_ms": 4000,
      "extracted_text": "1. Mean-Field Variational Inference\n2. VI Application\n\nboostcamp aitech\n© NAVER Connect Foundation\n2\n\n- 본 슬라이드는 강의의 주요 구성 요소를 나열한 목록이다.\n- 두 가지 주요 주제로 구성되어 있으며, 1번은 \"Mean-Field Variational Inference\", 2번은 \"VI Application\"이다.\n- 페이지 번호는 2번을 나타내며, `boostcamp aitech` 로고와 `NAVER Connect Foundation` 저작권 표시가 하단에 위치한다."
    },
    {
      "timestamp_ms": 37000,
      "extracted_text": "1. Mean-Field Variational Inference\n\n변분추론 중, Mean-Field Variational Inference의 개념 학습 완료\n\nboostcamp aitech\n© NAVER Connect Foundation\n3\n\n- 슬라이드 제목은 여전히 \"1. Mean-Field Variational Inference\"이다.\n- 본 슬라이드는 현재 강의의 진행 상황을 설명하며, \"변분추론 중, Mean-Field Variational Inference의 개념 학습 완료\"라고 명시하고 있다.\n- 페이지 번호는 3번이며, 하단에 동일한 로고와 저작권 정보가 포함되어 있다."
    },
    {
      "timestamp_ms": 45000,
      "extracted_text": "### 1.1 MFVI 수식유도 준비과정\n\n- derivation 2) functional derivative\n\n$$\n\\begin{aligned}\nELBO &= \\int q_j \\left\\{ \\int \\log p(x, z) \\prod_{i \\neq j} q_i dz_i \\right\\} dz_j - \\int q_j \\log q_j dz_j + C \\\\\n&= \\int q_j E_{i \\neq j}[\\log p(x, z)] dz_j - \\int q_j \\log q_j dz_j + C\n\\end{aligned}\n$$\n\n$$\nq_j^* = \\argmax_{q_j} ELBO = \\argmax_{q_j} \\int q_j E_{i \\neq j}[\\log p(x, z)] dz_j - \\int q_j \\log q_j dz_j\n$$\n\n### Functional derivative (variational derivative)\n- Functional: input is a function\n- Example) ELBO is a functional\n- Functional derivative: change in a functional to a change in a function on which the functional depends\n\n### Traditional calculus: R → f → R\n### Variational calculus: f(x) → f → R\n\n결국,\nFunctional의\n최대치를 구해야\n하는 상황입니다.\n\nboostcamp aitech\n© NAVER Connect Foundation\n4\n\n- 본 슬라이드는 Mean-Field Variational Inference(MFVI)의 수식 유도를 위한 준비 과정을 설명함.\n- `ELBO`의 수식이 두 가지 형태로 나열되어 있으며, 상수항은 무시함(`Ignore constant`).\n- `q_j^* = argmax_{q_j} ELBO`의 유도 과정이 포함됨.\n- Functional derivative에 대한 설명이 포함되어 있으며, 전통적 미적분(Traditional calculus)과 변분법(Variational calculus)의 차이를 명확히 구분함.\n- 오른쪽 상단의 툴팁은 \"결국, Functional의 최대치를 구해야 하는 상황입니다.\"라는 결론을 제시함."
    },
    {
      "timestamp_ms": 337000,
      "extracted_text": "### 1.1 MFVI 수식유도 준비과정\n\nTo find x corresponding to local minimum: Find f'(x) or dy/dx and set it to 0\n- solving f'(x) = 0 gives stationary points\n- further testing needed to determine their nature (min or max)\n\n![Graph showing a function f(x) with peaks and valleys on x-y axes](https://i.imgur.com/fake-graph.png)\n*(Note: Graph is manually described as a typical curve with local min/max points, labeled f(x) on y-axis and x on x-axis.)*\n\nIn summary\n- stationary points of function f(x), solve df/dx = 0 for x (regular calculus)\n- stationary functions of a functional I[f] (function of functions), solve (differential) equation for stationary function f(x) (calculus of variations)\n\nFunctional의\n최대치를 구하기\n위한 준비작업\n\nboostcamp aitech\n© NAVER Connect Foundation\n5\n\n- 본 슬라이드는 함수의 최소점 찾는 방법에서 시작하여, 함수의 함수인 Functional의 최대치를 찾는 변분법으로의 연계를 설명한다.\n- 그래프는 `f(x)`의 일반적인 형태를 나타내며, 정지점(stationary points)이 존재함을 시각화함.\n- 요약 부분에서는 일반적 미적분(regular calculus)과 변분법(calculus of variations)의 접근 방식을 비교함.\n  - 일반 함수의 정지점: `df/dx = 0`을 풀어 x를 찾음\n  - Functional의 정지 함수: 미분 방정식을 풀어 정지 함수 `f(x)`를 찾음\n- 오른쪽 상단 툴팁은 \"Functional의 최대치를 구하기 위한 준비작업\"임을 강조함."
    }
  ]
}
