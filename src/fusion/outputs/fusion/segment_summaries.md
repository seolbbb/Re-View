### Segment 1 (00:00–00:37)
- 요약
  - (1-1) Variational Inference (변분 추론)의 다양한 유도 방법과 심화 내용을 학습한다.
    - evidence: transcript=[t1], visual=[]
    - confidence: high
  - (1-2) Mean-field Variational Inference (MFVI)를 다르게 유도하는 방법을 살펴본다.
    - evidence: transcript=[t2], visual=[v2]
    - confidence: high
  - (1-3) Variational Inference (VI)가 실제 환경에서 어떻게 application (어플리케이션) 되는지 확인한다.
    - evidence: transcript=[t3], visual=[v2]
    - confidence: high
  - (1-4) Expectation-Maximization (EM) 알고리즘의 정의와 특징을 다룬다.
    - evidence: transcript=[t4], visual=[]
    - confidence: high
  - (1-5) EM 알고리즘과 VI 사이의 공통점과 차이점 및 두 개념 사이의 깊은 관련성을 분석한다.
    - evidence: transcript=[t5], visual=[]
    - confidence: high
- 정의
  - Mean-field Variational Inference (MFVI): 변분 추론의 한 종류로, 이번 강의에서 개념 학습을 완료하고 새로운 유도 방법을 배울 대상이다.
    - evidence: transcript=[t2], visual=[v2]
    - confidence: high
  - Expectation-Maximization (EM): 익스펙테이션 n 맥시마이제이션으로 불리는 알고리즘으로, VI와 밀접한 관련이 있다.
    - evidence: transcript=[t4,t5], visual=[]
    - confidence: high
- 해설
  - 강의의 전반적인 구성은 MFVI의 심화 유도와 VI의 실제 적용 사례를 다루는 데 집중되어 있습니다.
    - evidence: transcript=[t1,t2,t3], visual=[v2]
    - confidence: high
  - EM 알고리즘은 VI와 비교 분석될 핵심 개념으로 등장하며, 두 방법론이 서로 어떻게 연결되는지 파악하는 것이 중요합니다.
    - evidence: transcript=[t4,t5], visual=[]
    - confidence: high
- 확인 불가/열린 질문
  - EM 알고리즘과 VI는 구체적으로 어떤 수학적 구조를 공유하기에 깊은 관련이 있다고 하는가?
    - evidence: transcript=[t5], visual=[]
    - confidence: medium

### Segment 2 (00:37–01:48)
- 요약
  - (2-1) MFVI를 유도하기 위해 log p(x, z)의 기댓값 등을 활용하는 트릭을 사용한다.
    - evidence: transcript=[t4], visual=[v2]
    - confidence: high
  - (2-2) Evidence Lower Bound (ELBO) 또는 log marginal likelihood (로그 마지널 라이클리후드)의 하한을 최대화하는 것이 목표이다.
    - evidence: transcript=[t5,t7], visual=[]
    - confidence: high
  - (2-3) ELBO를 최대화하기 위한 최적의 q를 찾는 과정이 MFVI의 핵심이다.
    - evidence: transcript=[t6,t7], visual=[]
    - confidence: high
  - (2-4) 이상적인 q는 posterior (사후 확률)이지만, 이를 정확히 구할 수 없는 경우가 많다.
    - evidence: transcript=[t8], visual=[]
    - confidence: high
  - (2-5) ELBO를 최대화함으로써 q를 posterior에 가깝게 만들 수 있다.
    - evidence: transcript=[t9], visual=[]
    - confidence: high
  - (2-6) Functional derivative (변분 미분)는 함수를 입력으로 받아 실수를 출력하는 functional의 변화를 다룬다.
    - evidence: transcript=[], visual=[v2]
    - confidence: high
  - (2-7) 전통적인 미적분은 실수를 입력으로 받지만, 변분법은 함수 자체를 입력으로 취급한다.
    - evidence: transcript=[], visual=[v2]
    - confidence: high
- 정의
  - Evidence Lower Bound (ELBO): log marginal likelihood의 로어 바운드로, 이를 최대화하여 q를 posterior에 근사시킨다.
    - evidence: transcript=[t5,t7,t9], visual=[]
    - confidence: high
  - Functional derivative (변분 미분): 입력이 함수인 functional에서, 해당 함수가 변할 때 functional이 어떻게 변하는지 측정하는 것이다.
    - evidence: transcript=[], visual=[v2]
    - confidence: high
- 해설
  - ELBO 수식에서 q_j^*를 구하는 과정은 ELBO라는 functional을 최대화하는 q_j를 찾는 argmax 연산으로 표현됩니다.
    - evidence: transcript=[], visual=[v2]
    - confidence: high
  - 우리가 posterior를 직접 구할 수 없기 때문에, 대신 계산 가능한 ELBO를 최대화하여 간접적으로 posterior에 접근하는 전략을 취합니다.
    - evidence: transcript=[t8,t9], visual=[]
    - confidence: high
- 확인 불가/열린 질문
  - ELBO를 최대화하는 것이 어떻게 q를 posterior에 가깝게 만드는 수학적 보장이 되는가?
    - evidence: transcript=[t9], visual=[]
    - confidence: medium

### Segment 3 (01:48–03:04)
- 요약
  - (3-1) Posterior를 정확히 구할 수 없으므로 ELBO를 최대화하는 q를 찾는 것이 목적이다.
    - evidence: transcript=[t1], visual=[]
    - confidence: high
  - (3-2) 변수가 많아질수록 q의 구조가 매우 복잡해질 수 있다.
    - evidence: transcript=[t2,t4], visual=[]
    - confidence: high
  - (3-3) q_j는 전체 latent variable (레이턴트 베리어블) 중 일부를 나타내는 간소화된 버전이다.
    - evidence: transcript=[t3,t5], visual=[]
    - confidence: high
  - (3-4) Latent Dirichlet Allocation (LDA)와 같이 latent variable이 여러 개인 모델은 직접적인 유도가 어렵다.
    - evidence: transcript=[t6], visual=[]
    - confidence: high
  - (3-5) 서로 다른 분포(Gaussian, Dirichlet, Multinomial)를 따르는 변수들의 joint (조인트) 분포를 정의하기 어렵다.
    - evidence: transcript=[t7,t8], visual=[]
    - confidence: high
  - (3-6) 복잡한 문제를 해결하기 위해 q를 q1, q2, q3와 같이 각각 쪼개서 분석한다.
    - evidence: transcript=[t9], visual=[]
    - confidence: high
  - (3-7) ELBO 수식 내의 기댓값 E_{i != j}는 j를 제외한 나머지 변수들에 대한 평균을 의미한다.
    - evidence: transcript=[], visual=[v1]
    - confidence: high
- 정의
  - Latent Dirichlet Allocation (LDA): 여러 개의 latent variable을 포함하고 있어 q를 직접 정의하거나 유도하기 어려운 모델의 예시이다.
    - evidence: transcript=[t6], visual=[]
    - confidence: high
  - latent variable (잠재 변수): 데이터 이외의 관측되지 않는 변수들로, VI를 통해 이들의 분포를 추정하고자 한다.
    - evidence: transcript=[t5], visual=[]
    - confidence: high
- 해설
  - ELBO 수식에서 적분 기호와 프로덕트 기호(Π)가 사용된 이유는 여러 q_i들의 결합을 나타내기 위함이며, 특정 q_j에 대해 최적화하기 위해 나머지를 분리합니다.
    - evidence: transcript=[], visual=[v1]
    - confidence: high
  - 서로 다른 확률 분포를 따르는 변수들이 섞여 있을 때 그들의 joint 분포를 하나로 정의하는 것은 불가능에 가깝기 때문에, 각 변수별로 q를 쪼개는 Mean-field 가정이 필요합니다.
    - evidence: transcript=[t7,t8,t9], visual=[]
    - confidence: high
- 확인 불가/열린 질문
  - q를 개별적으로 쪼개서 분석할 때, 변수들 사이의 상관관계가 무시되는 문제는 어떻게 해결하는가?
    - evidence: transcript=[t9], visual=[]
    - confidence: low
    - notes: 입력 내용 기반 추론

### Segment 4 (03:04–04:17)
- 요약
  - (4-1) 각각의 q를 독립적으로 최대화하려는 시도가 Mean-field assumption (민 필드 어썸션)의 핵심이다.
    - evidence: transcript=[t1], visual=[]
    - confidence: high
  - (4-2) MFVI를 유도하는 세 번째 방법으로 functional derivative를 상세히 살펴본다.
    - evidence: transcript=[t2,t3], visual=[]
    - confidence: high
  - (4-3) Variational calculus (변분법)는 일반적인 미적분과 달리 함수를 입력으로 받는다.
    - evidence: transcript=[t6,t8], visual=[v1]
    - confidence: high
  - (4-4) 일반적인 calculus (미적분)는 실수를 입력받아 실수를 출력하는 함수를 다룬다.
    - evidence: transcript=[t7], visual=[v1]
    - confidence: high
  - (4-5) Functional (펑셔널)은 함수 f(x)를 입력으로 받아 실수를 내뱉는 '함수에 대한 함수'이다.
    - evidence: transcript=[t8,t9], visual=[v1]
    - confidence: high
  - (4-6) Functional derivative는 VI뿐만 아니라 다양한 분야에서 광범위하게 사용되는 도구이다.
    - evidence: transcript=[t4,t5], visual=[]
    - confidence: high
  - (4-7) 결국 우리가 해결해야 할 문제는 functional의 최대치를 구하는 상황으로 귀결된다.
    - evidence: transcript=[], visual=[v1]
    - confidence: high
- 정의
  - Mean-field assumption (민 필드 가정): 복잡한 joint 분포를 개별적인 q들의 곱으로 분리하여 각각을 최대화할 수 있다고 가정하는 사항이다.
    - evidence: transcript=[t1], visual=[]
    - confidence: high
  - Variational calculus (변분법): 입력이 함수인 functional을 다루는 미적분학의 한 분야이다.
    - evidence: transcript=[t8], visual=[v1]
    - confidence: high
- 해설
  - 전통적인 미적분(Traditional calculus)이 R에서 R로의 매핑을 다룬다면, 변분법(Variational calculus)은 함수 공간에서 R로의 매핑을 다룬다는 차이가 있습니다.
    - evidence: transcript=[], visual=[v1]
    - confidence: high
  - Functional derivative가 필요한 이유는 우리가 최적화하려는 대상인 ELBO 자체가 특정 값이 아닌 '함수 q'에 의존하는 functional이기 때문입니다.
    - evidence: transcript=[t8,t9], visual=[v1]
    - confidence: high
- 확인 불가/열린 질문
  - 함수를 입력으로 받는 functional의 미분은 일반적인 함수의 미분법과 계산 방식에서 어떤 차이가 있는가?
    - evidence: transcript=[t6], visual=[v1]
    - confidence: medium

### Segment 5 (04:17–05:37)
- 요약
  - (5-1) f(x)를 입력으로 받는 f는 '함수에 대한 함수'인 functional로 정의된다.
    - evidence: transcript=[t2,t3], visual=[]
    - confidence: high
  - (5-2) ELBO는 확률 분포 함수 q_j를 입력으로 받아 값을 결정하므로 functional의 대표적인 예시이다.
    - evidence: transcript=[t4,t5,t6], visual=[v1]
    - confidence: high
  - (5-3) Functional derivative는 입력 함수가 변할 때 functional의 출력값이 어떻게 변하는지 그 변화량을 추정한다.
    - evidence: transcript=[t7,t8,t9], visual=[v1]
    - confidence: high
  - (5-4) Functional derivative는 variational derivative (변분 미분)라고도 불린다.
    - evidence: transcript=[t9], visual=[v1]
    - confidence: high
  - (5-5) 일반 미적분에서는 df/dx = 0을 풀어 stationary point (정지점)를 찾는다.
    - evidence: transcript=[], visual=[v1]
    - confidence: high
  - (5-6) 변분법에서는 미분 방정식을 풀어 functional을 정지시키는 stationary function (정지 함수) f(x)를 찾는다.
    - evidence: transcript=[], visual=[v1]
    - confidence: high
  - (5-7) Functional의 최대치를 구하기 위해 이러한 미분 개념들을 준비 과정으로 학습한다.
    - evidence: transcript=[t10], visual=[v1]
    - confidence: high
- 정의
  - Functional (펑셔널): 함수를 입력으로 받아 실수를 출력하는 함수로, ELBO가 이에 해당한다.
    - evidence: transcript=[t3,t6], visual=[v1]
    - confidence: high
  - stationary function (정지 함수): Functional의 변화율이 0이 되게 하는 함수로, 변분법의 미분 방정식을 통해 구한다.
    - evidence: transcript=[], visual=[v1]
    - confidence: high
- 해설
  - ELBO 수식에서 q_j가 가우시안 분포와 같은 함수 형태를 띠고 있으며, 이 함수 전체가 ELBO의 입력이 되기 때문에 ELBO를 functional이라고 부릅니다.
    - evidence: transcript=[t4,t5,t6], visual=[]
    - confidence: high
  - 일반 미적분은 최적의 '지점(point)'을 찾지만, 변분법은 최적의 '함수(function)' 자체를 찾는다는 점이 가장 큰 차이입니다.
    - evidence: transcript=[], visual=[v1]
    - confidence: high
- 확인 불가/열린 질문
  - ELBO를 최대화하는 stationary function을 찾았을 때, 그것이 항상 전역 최댓값임을 어떻게 보장할 수 있는가?
    - evidence: transcript=[], visual=[v1]
    - confidence: low
    - notes: v1에서 추가 테스트가 필요하다고 언급됨

### Segment 6 (05:37–06:05)
- 요약
  - (6-1) 함수 f(x)에서 최대가 되는 x를 찾기 위해 미분값 f'(x)가 0이 되는 지점을 활용한다.
    - evidence: transcript=[t2], visual=[v1]
    - confidence: high
  - (6-2) f'(x) = 0을 만족하는 지점을 stationary point라고 정의한다.
    - evidence: transcript=[t3], visual=[v1]
    - confidence: high
  - (6-3) Stationary point를 찾은 후에는 해당 점이 극대(max)인지 극소(min)인지 판별하는 추가 과정이 필요할 수 있다.
    - evidence: transcript=[], visual=[v1]
    - confidence: high
- 정의
  - stationary point (정지점): 함수의 도함수 f'(x) 또는 dy/dx가 0이 되는 지점을 의미한다.
    - evidence: transcript=[t3], visual=[v1]
    - confidence: high
- 해설
  - 일반적인 미적분학에서 함수의 최댓값을 찾는 가장 기본적인 방법은 도함수를 0으로 만드는 x값을 구하는 것입니다.
    - evidence: transcript=[t2,t3], visual=[v1]
    - confidence: high
  - 이 과정은 functional의 최대치를 구하기 위한 변분법적 접근을 이해하기 위한 기초적인 준비 단계에 해당합니다.
    - evidence: transcript=[t1], visual=[v1]
    - confidence: high
- 확인 불가/열린 질문
  - Stationary point가 여러 개 존재할 경우, 그중에서 실제 최대치를 어떻게 특정할 수 있는가?
    - evidence: transcript=[], visual=[v1]
    - confidence: medium

