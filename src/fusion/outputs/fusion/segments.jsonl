{"end_ms": 37000, "run_id": "run_26aa2772f34e", "segment_id": 1, "start_ms": 0, "transcript_text": "변분 추론에 좀 더 다른 유도 방법 그다음에 심화들을 한번 살펴보도록 하겠습니다.\n저희가 민필드 밸리션 인퍼런스가 무엇인지 한번 살펴봤었는데요. 자 그거를 우리가 또 다르게도 한번 유도를 해볼 수가 있습니다.\n그 내용을 한번 살펴보도록 하고 그다음에 그러한 베니션 인퍼런스가 어떻게 좀 어플리케이션 되는지 그다음에\n여러분들께서 사실 EM 알고리즘을 아마 많이 들어보셨을 것 같아요. 그쵸 익스펙테이션 n 맥시마이제이션 알고리즘으로 불리는\n그런 EM 알고리즘하고 뭐가 다르고 뭐가 같은 건지 두 개가 또 굉장히 또 깊이 관련이 있습니다. 한번 살펴보도록 하겠습니다.", "visual_text": "[ML for RecSys]\n**변분추론 II**\n---\n송경우\n연세대학교 응용통계학과, 통계데이터사이언스학과\nWARNING: 본 교육 콘텐츠의 저작재산권은 제단법인 네이버커넥트에 귀속됩니다. 본 콘텐츠를 어떠한 경로로든 외부로 유출 및 수정하는 행위를 엄격히 금합니다. 다만, 비영리적 교육 및 연구활동에 한정되어 사용할 수 있으나 제단의 허락을 받아야 합니다. 이를 위반하는 경우, 관련 법률에 따라 책임을 질 수 있습니다.\nboostcamp aitech\n© NAVER Connect Foundation\n- 이미지 상단에는 `[ML for RecSys]`와 `변분추론 II`라는 제목이 표시되어 있으며, 강의 제목과 주제를 나타낸다.\n- 강사 정보는 송경우 교수로, 연세대학교 응용통계학과 및 통계데이터사이언스학과 소속임.\n- 하단에는 저작권 경고 문구와 `boostcamp aitech`, `NAVER Connect Foundation` 로고가 포함되어 있다.\n1. Mean-Field Variational Inference\n2. VI Application\n- 본 슬라이드는 강의의 주요 구성 요소를 나열한 목록이다.\n- 두 가지 주요 주제로 구성되어 있으며, 1번은 \"Mean-Field Variational Inference\", 2번은 \"VI Application\"이다.\n- 페이지 번호는 2번을 나타내며, `boostcamp aitech` 로고와 `NAVER Connect Foundation` 저작권 표시가 하단에 위치한다."}
{"end_ms": 108835, "run_id": "run_26aa2772f34e", "segment_id": 2, "start_ms": 37000, "transcript_text": "그런 EM 알고리즘하고 뭐가 다르고 뭐가 같은 건지 두 개가 또 굉장히 또 깊이 관련이 있습니다. 한번 살펴보도록 하겠습니다.\n그래서 첫 번째 파트는 저희가 엠프브i를 좀 더 한 번 더 보도록 하겠습니다.\n자 엠프브i를 저희가 유도하는 과정을 앞서서 한번 살펴본 적이 있습니다.\n그렇죠 그래서 뭐 로그의 피 틸다를 이용해서 하기도 하고 로그의 피에 로그 익스포넨셜을 같이 써가지고 그런 트릭을 이용해서\n그래서 이런 엘보 로어바운드 또는 로그 마시널 라이클루더의 로어 바운드를 우리가 맥시마이즈 하기 위해서\n어떤 큐를 잡아야 되는가를 우리가 유도를 했었습니다. 지금 우리가 이걸 계속하고 있는 이유는 뭡니까?\n우리는 이런 로어바운드를 맥시마이즈 하고 싶은 거예요. 그렇죠 그러면 그러한 로어 바운드를 우리가 맥시마이즈 하기 위한 q는 뭐냐라고 했습니다.\n답은 간단해요. 포스테리어입니다. 근데 포스테리오를 우리는 정확하게 구할 수가 없어요. 그래서 우리가 대신에\n얘를 맥시마이즈 시키면 우리가 q가 포스테리어에 가까워질 것이다라고 또는 우리가 포스테리어를 잡으면 얘가 로그 마실라이 크로즈에 가까워지지만", "visual_text": "1. Mean-Field Variational Inference\n변분추론 중, Mean-Field Variational Inference의 개념 학습 완료\nboostcamp aitech\n© NAVER Connect Foundation\n- 슬라이드 제목은 여전히 \"1. Mean-Field Variational Inference\"이다.\n- 본 슬라이드는 현재 강의의 진행 상황을 설명하며, \"변분추론 중, Mean-Field Variational Inference의 개념 학습 완료\"라고 명시하고 있다.\n- 페이지 번호는 3번이며, 하단에 동일한 로고와 저작권 정보가 포함되어 있다.\n### 1.1 MFVI 수식유도 준비과정\n- derivation 2) functional derivative\n\\begin{aligned}\nELBO &= \\int q_j \\left\\{ \\int \\log p(x, z) \\prod_{i \\neq j} q_i dz_i \\right\\} dz_j - \\int q_j \\log q_j dz_j + C \\\\\n&= \\int q_j E_{i \\neq j}[\\log p(x, z)] dz_j - \\int q_j \\log q_j dz_j + C\n\\end{aligned}\nq_j^* = \\argmax_{q_j} ELBO = \\argmax_{q_j} \\int q_j E_{i \\neq j}[\\log p(x, z)] dz_j - \\int q_j \\log q_j dz_j\n### Functional derivative (variational derivative)\n- Functional: input is a function\n- Example) ELBO is a functional\n- Functional derivative: change in a functional to a change in a function on which the functional depends\n### Traditional calculus: R → f → R\n### Variational calculus: f(x) → f → R\n결국,\nFunctional의\n최대치를 구해야\n하는 상황입니다.\n- 본 슬라이드는 Mean-Field Variational Inference(MFVI)의 수식 유도를 위한 준비 과정을 설명함.\n- `ELBO`의 수식이 두 가지 형태로 나열되어 있으며, 상수항은 무시함(`Ignore constant`).\n- `q_j^* = argmax_{q_j} ELBO`의 유도 과정이 포함됨.\n- Functional derivative에 대한 설명이 포함되어 있으며, 전통적 미적분(Traditional calculus)과 변분법(Variational calculus)의 차이를 명확히 구분함.\n- 오른쪽 상단의 툴팁은 \"결국, Functional의 최대치를 구해야 하는 상황입니다.\"라는 결론을 제시함."}
{"end_ms": 184320, "run_id": "run_26aa2772f34e", "segment_id": 3, "start_ms": 108835, "transcript_text": "여기서는 저희가 포스트를 정확하게 못 구하기 때문에 얘를 맥시마이즈 하는 결국 큐가 뭐냐를 찾고 싶은 거예요.\n근데 그 q가 굉장히 복잡해질 수 있다라고 말씀을 드렸습니다. 언제 여기 나와 있는 q j는 q z 제에\n좀 더 이제 간단화된 버전으로 생각하시면 됩니다. 그걸 그냥 편의상 q의 z j를 qj라고 그냥 쓴 것뿐입니다.\n그러면은 원래는 이제 큐 제가 아니라 큐 제라고 하면 큐 제 전체 그러면은 변수가 엄청 여러 개 있을 수 있는 거예요.\n여기서 제는 레이턴트 베리어블 즉 스가 아닌 나머지 모든 걸 다 의미하는 거라고 했으니까 우리한테 레이턴트 베리어블이 여러 개인\n예제도 하나 봤었죠. 앞에서 레이턴 디리클레 얼로케이션 LD라고 부르는 그러한 것들은 우리가 유도를 못하는 겁니다.\n왜 이 큐라는 거 자체를 정의를 못해서 그 여러 변수들 간의 조인트 어떤 거는 가우시안 따르고 어떤 거는 또 드리클레 따르고 어떤 건 또 멀티노미얼 따르고\n그러한 서로 다른 랜덤 베어러블의 조인트는 무슨 분포냐 말 못 하거든요.\n그래서 우리가 각각 쪼개서 보겠다 q 제 1 제 2 제 3 각각 쪼개서 보겠다", "visual_text": "### 1.1 MFVI 수식유도 준비과정\n- derivation 2) functional derivative\n\\begin{aligned}\nELBO &= \\int q_j \\left\\{ \\int \\log p(x, z) \\prod_{i \\neq j} q_i dz_i \\right\\} dz_j - \\int q_j \\log q_j dz_j + C \\\\\n&= \\int q_j E_{i \\neq j}[\\log p(x, z)] dz_j - \\int q_j \\log q_j dz_j + C\n\\end{aligned}\nq_j^* = \\argmax_{q_j} ELBO = \\argmax_{q_j} \\int q_j E_{i \\neq j}[\\log p(x, z)] dz_j - \\int q_j \\log q_j dz_j\n### Functional derivative (variational derivative)\n- Functional: input is a function\n- Example) ELBO is a functional\n- Functional derivative: change in a functional to a change in a function on which the functional depends\n### Traditional calculus: R → f → R\n### Variational calculus: f(x) → f → R\n결국,\nFunctional의\n최대치를 구해야\n하는 상황입니다.\nboostcamp aitech\n© NAVER Connect Foundation\n- 본 슬라이드는 Mean-Field Variational Inference(MFVI)의 수식 유도를 위한 준비 과정을 설명함.\n- `ELBO`의 수식이 두 가지 형태로 나열되어 있으며, 상수항은 무시함(`Ignore constant`).\n- `q_j^* = argmax_{q_j} ELBO`의 유도 과정이 포함됨.\n- Functional derivative에 대한 설명이 포함되어 있으며, 전통적 미적분(Traditional calculus)과 변분법(Variational calculus)의 차이를 명확히 구분함.\n- 오른쪽 상단의 툴팁은 \"결국, Functional의 최대치를 구해야 하는 상황입니다.\"라는 결론을 제시함."}
{"end_ms": 257740, "run_id": "run_26aa2772f34e", "segment_id": 4, "start_ms": 184320, "transcript_text": "라는 게 민 필드 어썸션이었습니다. 가정 사항인 거죠. 어디까지나 그러고 나서 그 각각의 q를 우리가 맥시마이즈 하는 걸 찾겠다\n라는 게 우리의 목표였습니다. 그리고 그거를 두 가지 방법으로 우리가 유도를 했었어요. 오늘은 그 세 번째 방법\n펑셔널 딜리버티브를 한번 살펴보도록 하겠습니다.\n지금 우리가 볼 거는 펑션 펑셔널 그다음에 펑셔널 또는 베리셔널 디리버티브까지 볼 건데 이거는\n지금 우리가 보는 베리에이션 인퍼런스에서뿐만 아니라 굉장히 많은 곳에서 쓰입니다. 그래서 여러분들께서\n꼭 기억하고 넘어가시면 좋겠습니다. 일반적인 카큘러스랑 뭐가 다르냐 일반적인 여러분들께서 배웠을 미적분이랑 뭐가 다르냐\n자 그거는 실수를 인풋으로 받습니다. 그리고 실수가 아웃풋으로 나옵니다. 그런 함수가 있는 거예요. 근데 베리션 칼큘러스는 뭐냐면\n함수를 인풋으로 받아요. 함수를 그러고 나서 실수를 내뱉습니다. 인풋이 함수예요. 그러면\n여기 나와 있는 f는 뭐라고 부르면 될까요? 이 f는 FX에 대한 함수인 거잖아요. 여기 f를 우리가 뭐라고 불러요? 여기 나와 있는 f를", "visual_text": "### 1.1 MFVI 수식유도 준비과정\n- derivation 2) functional derivative\n\\begin{aligned}\nELBO &= \\int q_j \\left\\{ \\int \\log p(x, z) \\prod_{i \\neq j} q_i dz_i \\right\\} dz_j - \\int q_j \\log q_j dz_j + C \\\\\n&= \\int q_j E_{i \\neq j}[\\log p(x, z)] dz_j - \\int q_j \\log q_j dz_j + C\n\\end{aligned}\nq_j^* = \\argmax_{q_j} ELBO = \\argmax_{q_j} \\int q_j E_{i \\neq j}[\\log p(x, z)] dz_j - \\int q_j \\log q_j dz_j\n### Functional derivative (variational derivative)\n- Functional: input is a function\n- Example) ELBO is a functional\n- Functional derivative: change in a functional to a change in a function on which the functional depends\n### Traditional calculus: R → f → R\n### Variational calculus: f(x) → f → R\n결국,\nFunctional의\n최대치를 구해야\n하는 상황입니다.\nboostcamp aitech\n© NAVER Connect Foundation\n- 본 슬라이드는 Mean-Field Variational Inference(MFVI)의 수식 유도를 위한 준비 과정을 설명함.\n- `ELBO`의 수식이 두 가지 형태로 나열되어 있으며, 상수항은 무시함(`Ignore constant`).\n- `q_j^* = argmax_{q_j} ELBO`의 유도 과정이 포함됨.\n- Functional derivative에 대한 설명이 포함되어 있으며, 전통적 미적분(Traditional calculus)과 변분법(Variational calculus)의 차이를 명확히 구분함.\n- 오른쪽 상단의 툴팁은 \"결국, Functional의 최대치를 구해야 하는 상황입니다.\"라는 결론을 제시함."}
{"end_ms": 337000, "run_id": "run_26aa2772f34e", "segment_id": 5, "start_ms": 257740, "transcript_text": "이 인풋에 대한 함수 실수에 대한 함수 또는 x에 대한 함수라고 부르죠. 그쵸 근데 여기는 이 f가\nFX를 인풋으로 받으니까 FX에 대한 함수인 거예요. 여기 나와 있는 f는 그러면 어떻게 됩니까? 함수에 대한 함수인 거예요.\n그거는 우리가 펑셔널이라고 부릅니다. 펑셔널 그럼 여기서 한번 보시면\n엘보라는 것은 여기서 큐라는 건 우리가 예를 들어 어떤 거라고 했습니까? 가우시안 분포라고 했습니다. 큐 제는 가우시안 분포예요. 그쵸\n그러면은 그러한 q 제를 우리가 인풋으로 받아서 함수로 만든 게 엘버입니다. 그쵸 엘버는 이 q j에 대한 함수인 거잖아요.\n함수에 대한 함수다. 그러면 여기서 엘버를 우리가 펑셔널이라고 말할 수가 있겠습니다. 그럼 여기서 펑셔널 디리비티는 뭐냐면\n결국 우리가 여기서 q 함수를 변화시킬 때 결국 여러분 디리버티브라는 건 뭐예요?\n우리가 인풋을 변화시켰을 때 아웃풋이 어떻게 변하는지 그 변화량을 우리가 추정하는 것입니다. 그러면 여기서는 펑셔널 디리버티브는\n함수가 변했을 때 펑셔널이 어떻게 변하는지를 추정하는 게 펑셔널 디리버티브 또는 베르셔널 디리뷰티브라고 부릅니다.\n아시겠죠? 펑셔널 딜리브티브를 우리가 가기 전에 좀 몇 가지 준비 과정을 거치고 넘어가도록 하겠습니다.", "visual_text": "### 1.1 MFVI 수식유도 준비과정\nTo find x corresponding to local minimum: Find f'(x) or dy/dx and set it to 0\n- solving f'(x) = 0 gives stationary points\n- further testing needed to determine their nature (min or max)\n![Graph showing a function f(x) with peaks and valleys on x-y axes](https://i.imgur.com/fake-graph.png)\n*(Note: Graph is manually described as a typical curve with local min/max points, labeled f(x) on y-axis and x on x-axis.)*\nIn summary\n- stationary points of function f(x), solve df/dx = 0 for x (regular calculus)\n- stationary functions of a functional I[f] (function of functions), solve (differential) equation for stationary function f(x) (calculus of variations)\nFunctional의\n최대치를 구하기\n위한 준비작업\nboostcamp aitech\n© NAVER Connect Foundation\n- 본 슬라이드는 함수의 최소점 찾는 방법에서 시작하여, 함수의 함수인 Functional의 최대치를 찾는 변분법으로의 연계를 설명한다.\n- 그래프는 `f(x)`의 일반적인 형태를 나타내며, 정지점(stationary points)이 존재함을 시각화함.\n- 요약 부분에서는 일반적 미적분(regular calculus)과 변분법(calculus of variations)의 접근 방식을 비교함.\n- 일반 함수의 정지점: `df/dx = 0`을 풀어 x를 찾음\n- Functional의 정지 함수: 미분 방정식을 풀어 정지 함수 `f(x)`를 찾음\n- 오른쪽 상단 툴팁은 \"Functional의 최대치를 구하기 위한 준비작업\"임을 강조함."}
{"end_ms": 365470, "run_id": "run_26aa2772f34e", "segment_id": 6, "start_ms": 337000, "transcript_text": "아시겠죠? 펑셔널 딜리브티브를 우리가 가기 전에 좀 몇 가지 준비 과정을 거치고 넘어가도록 하겠습니다.\n자 우리가 일반적으로 뭐 이러한 프스에서 최대가 되는 스를 찾고 싶다 너무 쉽죠 이거는 그냥 프프라임 x가 0이 되는 포인트를 찾으면 되는 거 아닙니까?\n그러한 스텐셔놀리 포인트를 찾으면 끝이네요라고 말하죠. 정답입니다. 맞아요. 그쵸 여기서 최대가 되는 x 찾는다 그러면은 이분을 때 0 되는 스텐셔놀리 포인트.", "visual_text": "### 1.1 MFVI 수식유도 준비과정\nTo find x corresponding to local minimum: Find f'(x) or dy/dx and set it to 0\n- solving f'(x) = 0 gives stationary points\n- further testing needed to determine their nature (min or max)\n![Graph showing a function f(x) with peaks and valleys on x-y axes](https://i.imgur.com/fake-graph.png)\n*(Note: Graph is manually described as a typical curve with local min/max points, labeled f(x) on y-axis and x on x-axis.)*\nIn summary\n- stationary points of function f(x), solve df/dx = 0 for x (regular calculus)\n- stationary functions of a functional I[f] (function of functions), solve (differential) equation for stationary function f(x) (calculus of variations)\nFunctional의\n최대치를 구하기\n위한 준비작업\nboostcamp aitech\n© NAVER Connect Foundation\n- 본 슬라이드는 함수의 최소점 찾는 방법에서 시작하여, 함수의 함수인 Functional의 최대치를 찾는 변분법으로의 연계를 설명한다.\n- 그래프는 `f(x)`의 일반적인 형태를 나타내며, 정지점(stationary points)이 존재함을 시각화함.\n- 요약 부분에서는 일반적 미적분(regular calculus)과 변분법(calculus of variations)의 접근 방식을 비교함.\n- 일반 함수의 정지점: `df/dx = 0`을 풀어 x를 찾음\n- Functional의 정지 함수: 미분 방정식을 풀어 정지 함수 `f(x)`를 찾음\n- 오른쪽 상단 툴팁은 \"Functional의 최대치를 구하기 위한 준비작업\"임을 강조함."}
