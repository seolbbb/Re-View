"""
================================================================================
run_video_pipeline.py - ë¹„ë””ì˜¤ íŒŒì´í”„ë¼ì¸ ë²¤ì¹˜ë§ˆí¬ ë„êµ¬
================================================================================

[ëª©ì ]
    ë¹„ë””ì˜¤ 1ê°œ ì…ë ¥ â†’ STT/Capture/VLM â†’ Fusion ìš”ì•½ê¹Œì§€ end-to-end ì‹¤í–‰í•˜ë©°
    ê° ë‹¨ê³„ë³„ ì²˜ë¦¬ ì‹œê°„ì„ ì •ë°€í•˜ê²Œ ì¸¡ì •í•˜ì—¬ ë²¤ì¹˜ë§ˆí¬ ë¦¬í¬íŠ¸ë¥¼ ìƒì„±í•©ë‹ˆë‹¤.

[ì‚¬ìš©ë²•]
    python src/run_video_pipeline.py --video <video_path> [ì˜µì…˜...]

[ì¶œë ¥]
    - pipeline_run.json: ìƒì„¸í•œ ë²¤ì¹˜ë§ˆí¬ ë©”íŠ¸ë¦­ (JSON)
    - benchmark_report.md: ì‚¬ëŒì´ ì½ê¸° ì‰¬ìš´ ë²¤ì¹˜ë§ˆí¬ ë¦¬í¬íŠ¸
    - í„°ë¯¸ë„: ì‹¤ì‹œê°„ ì§„í–‰ ìƒí™© ë° ìµœì¢… ë²¤ì¹˜ë§ˆí¬ ìš”ì•½

================================================================================
"""

from __future__ import annotations

import argparse
import json
import os
import re
import subprocess
from concurrent.futures import ThreadPoolExecutor
import sys
import time
from datetime import datetime, timezone
from pathlib import Path
from typing import Any, Dict, List, Optional, Tuple

import yaml

ROOT = Path(__file__).resolve().parents[1]
if str(ROOT) not in sys.path:
    sys.path.append(str(ROOT))


from src.audio.stt_router import STTRouter
from src.capture.process_content import process_single_video_capture
from src.fusion.config import load_config
from src.fusion.final_summary_composer import compose_final_summaries
from src.fusion.io_utils import ensure_output_root
from src.fusion.renderer import render_segment_summaries_md
from src.fusion.summarizer import run_summarizer
from src.fusion.sync_engine import run_sync_engine
from src.vlm.vlm_engine import OpenRouterVlmExtractor, write_vlm_raw_json
from src.vlm.vlm_fusion import convert_vlm_raw_to_fusion_vlm
from src.judge.judge import run_judge


# ============================================================
# ìœ í‹¸ë¦¬í‹° í•¨ìˆ˜
# ============================================================

def _sanitize_video_name(stem: str) -> str:
    """ë¹„ë””ì˜¤ íŒŒì¼ ì´ë¦„ì„ ì•ˆì „í•œ ë””ë ‰í† ë¦¬ ì´ë¦„ìœ¼ë¡œ ë³€í™˜."""
    value = stem.strip()
    value = re.sub(r"\s+", "_", value)
    value = re.sub(r"[^A-Za-z0-9ê°€-í£._-]+", "_", value)
    value = re.sub(r"_+", "_", value).strip("._-")
    if not value:
        return "video"
    return value[:80]


def _write_json(path: Path, payload: Any) -> None:
    """JSON íŒŒì¼ ì €ì¥."""
    path.parent.mkdir(parents=True, exist_ok=True)
    with path.open("w", encoding="utf-8") as handle:
        json.dump(payload, handle, ensure_ascii=False, indent=2, sort_keys=True)


def _utc_now_iso() -> str:
    """í˜„ì¬ UTC ì‹œê°„ì„ ISO í˜•ì‹ìœ¼ë¡œ ë°˜í™˜."""
    return datetime.now(timezone.utc).isoformat()


def _format_duration(seconds: float) -> str:
    """ì´ˆ ë‹¨ìœ„ë¥¼ 'Xm Xs' ë˜ëŠ” 'Xs' í˜•ì‹ìœ¼ë¡œ ë³€í™˜."""
    if seconds < 60:
        return f"{seconds:.1f}s"
    minutes = int(seconds // 60)
    secs = seconds % 60
    return f"{minutes}m {secs:.1f}s"


def _get_video_duration(video_path: Path) -> Optional[float]:
    """ffprobeë¥¼ ì‚¬ìš©í•˜ì—¬ ë¹„ë””ì˜¤ ê¸¸ì´(ì´ˆ)ë¥¼ ì¶”ì¶œ."""
    try:
        result = subprocess.run(
            [
                "ffprobe", "-v", "error",
                "-show_entries", "format=duration",
                "-of", "default=noprint_wrappers=1:nokey=1",
                str(video_path)
            ],
            capture_output=True,
            text=True,
            timeout=30
        )
        if result.returncode == 0 and result.stdout.strip():
            return float(result.stdout.strip())
    except (subprocess.TimeoutExpired, FileNotFoundError, ValueError):
        pass
    return None


def _get_video_info(video_path: Path) -> Dict[str, Any]:
    """ë¹„ë””ì˜¤ì˜ ìƒì„¸ ì •ë³´ë¥¼ ì¶”ì¶œ (ffprobe ì‚¬ìš©)."""
    info: Dict[str, Any] = {
        "duration_sec": None,
        "width": None,
        "height": None,
        "fps": None,
        "codec": None,
        "file_size_mb": round(video_path.stat().st_size / (1024 * 1024), 2) if video_path.exists() else None
    }
    
    try:
        result = subprocess.run(
            [
                "ffprobe", "-v", "error",
                "-select_streams", "v:0",
                "-show_entries", "stream=width,height,r_frame_rate,codec_name",
                "-show_entries", "format=duration",
                "-of", "json",
                str(video_path)
            ],
            capture_output=True,
            text=True,
            timeout=30
        )
        if result.returncode == 0:
            data = json.loads(result.stdout)
            
            # Format ì •ë³´
            if "format" in data and "duration" in data["format"]:
                info["duration_sec"] = float(data["format"]["duration"])
            
            # Stream ì •ë³´
            if "streams" in data and data["streams"]:
                stream = data["streams"][0]
                info["width"] = stream.get("width")
                info["height"] = stream.get("height")
                info["codec"] = stream.get("codec_name")
                
                # FPS ê³„ì‚° (r_frame_rateëŠ” "30/1" í˜•ì‹)
                fps_str = stream.get("r_frame_rate", "")
                if "/" in fps_str:
                    num, den = fps_str.split("/")
                    if int(den) > 0:
                        info["fps"] = round(int(num) / int(den), 2)
    except (subprocess.TimeoutExpired, FileNotFoundError, ValueError, json.JSONDecodeError):
        pass
    
    return info


# ============================================================
# íƒ€ì´ë° ì¸¡ì • í•¨ìˆ˜
# ============================================================

class BenchmarkTimer:
    """ë²¤ì¹˜ë§ˆí¬ íƒ€ì´ë° ê´€ë¦¬ í´ë˜ìŠ¤."""
    
    def __init__(self):
        self.stages: Dict[str, Dict[str, Any]] = {}
        self.total_start: float = 0.0
        self.total_end: float = 0.0
    
    def start_total(self) -> None:
        """ì „ì²´ íƒ€ì´ë¨¸ ì‹œì‘."""
        self.total_start = time.perf_counter()
    
    def end_total(self) -> None:
        """ì „ì²´ íƒ€ì´ë¨¸ ì¢…ë£Œ."""
        self.total_end = time.perf_counter()
    
    def time_stage(self, stage_name: str, func, *args, **kwargs) -> Tuple[Any, float]:
        """
        íŠ¹ì • ìŠ¤í…Œì´ì§€ë¥¼ ì‹¤í–‰í•˜ê³  ì‹œê°„ì„ ì¸¡ì •.
        
        Returns:
            (ê²°ê³¼, ì†Œìš”ì‹œê°„_ì´ˆ)
        """
        # ì‹œì‘ ë¡œê·¸
        print(f"  â³ {stage_name}: ì‹œì‘...", flush=True)
        
        start = time.perf_counter()
        result = func(*args, **kwargs)
        elapsed = time.perf_counter() - start
        
        self.stages[stage_name] = {
            "elapsed_sec": elapsed,
            "start_time": start,
            "end_time": start + elapsed
        }
        
        # ì™„ë£Œ ë¡œê·¸
        print(f"  âœ“ {stage_name}: {_format_duration(elapsed)}")
        
        return result, elapsed
    
    def record_stage(self, stage_name: str, elapsed: float) -> None:
        """ì´ë¯¸ ì¸¡ì •ëœ ìŠ¤í…Œì´ì§€ ì‹œê°„ ê¸°ë¡."""
        self.stages[stage_name] = {
            "elapsed_sec": elapsed,
            "start_time": None,
            "end_time": None
        }
    
    def get_total_elapsed(self) -> float:
        """ì „ì²´ ì†Œìš” ì‹œê°„ ë°˜í™˜."""
        return self.total_end - self.total_start
    
    def get_report(self, video_duration_sec: Optional[float] = None) -> Dict[str, Any]:
        """ë²¤ì¹˜ë§ˆí¬ ë¦¬í¬íŠ¸ ìƒì„±."""
        total_elapsed = self.get_total_elapsed()
        
        report: Dict[str, Any] = {
            "total_elapsed_sec": round(total_elapsed, 3),
            "total_elapsed_formatted": _format_duration(total_elapsed),
            "stages": {}
        }
        
        # Video duration ê¸°ë°˜ ë©”íŠ¸ë¦­
        if video_duration_sec and video_duration_sec > 0:
            report["video_duration_sec"] = round(video_duration_sec, 2)
            report["speed_ratio"] = round(total_elapsed / video_duration_sec, 2)
            report["realtime_factor"] = f"{report['speed_ratio']:.2f}x"
        
        # ê° ìŠ¤í…Œì´ì§€ë³„ ìƒì„¸
        for name, data in self.stages.items():
            elapsed = data["elapsed_sec"]
            pct = (elapsed / total_elapsed * 100) if total_elapsed > 0 else 0
            
            report["stages"][name] = {
                "elapsed_sec": round(elapsed, 3),
                "elapsed_formatted": _format_duration(elapsed),
                "percentage": round(pct, 1)
            }
        
        return report


# ============================================================
# íŒŒì´í”„ë¼ì¸ ë‹¨ê³„ ì‹¤í–‰ í•¨ìˆ˜
# ============================================================

def _generate_fusion_config(
    *,
    template_config: Path,
    output_config: Path,
    repo_root: Path,
    stt_json: Path,
    vlm_json: Path,
    manifest_json: Path,
    output_root: Path,
) -> None:
    """Fusion íŒŒì´í”„ë¼ì¸ìš© config.yaml ìƒì„±."""
    payload: Dict[str, Any]
    with template_config.open("r", encoding="utf-8") as handle:
        payload = yaml.safe_load(handle)

    def _rel(p: Path) -> str:
        try:
            return str(p.relative_to(repo_root)).replace("\\", "/")
        except ValueError:
            return str(p)

    payload["paths"] = {
        "stt_json": _rel(stt_json),
        "vlm_json": _rel(vlm_json),
        "captures_manifest_json": _rel(manifest_json),
        "output_root": _rel(output_root),
    }

    output_config.parent.mkdir(parents=True, exist_ok=True)
    output_config.write_text(
        yaml.safe_dump(payload, sort_keys=False, allow_unicode=True),
        encoding="utf-8",
    )


def _run_stt(video_path: Path, output_stt_json: Path, *, backend: str) -> None:
    """STT(Speech-to-Text) ì‹¤í–‰."""
    router = STTRouter(provider=backend)
    audio_output_path = output_stt_json.with_name(f"{video_path.stem}.wav")
    router.transcribe_media(
        video_path,
        provider=backend,
        audio_output_path=audio_output_path,
        mono_method="auto",
        output_path=output_stt_json,
    )


def _run_capture(
    video_path: Path,
    output_base: Path,
    *,
    threshold: float,
    dedupe_threshold: float,
    min_interval: float,
    verbose: bool,
    video_name: str,
) -> List[Dict[str, Any]]:
    """ìŠ¬ë¼ì´ë“œ ìº¡ì²˜ ì‹¤í–‰."""
    metadata = process_single_video_capture(
        str(video_path),
        str(output_base),
        scene_threshold=threshold,
        dedupe_threshold=dedupe_threshold,
        min_interval=min_interval
    )
    return metadata


def _run_vlm_openrouter(
    *,
    captures_dir: Path,
    manifest_json: Path,
    video_name: str,
    output_base: Path,
    batch_size: Optional[int],
    concurrency: int,
    show_progress: bool,
) -> int:
    """VLM(Vision Language Model) ì‹¤í–‰. ì²˜ë¦¬ëœ ì´ë¯¸ì§€ ìˆ˜ ë°˜í™˜."""
    extractor = OpenRouterVlmExtractor(video_name=video_name, output_root=output_base)
    if batch_size is not None and batch_size < 1:
        raise ValueError("batch_sizeëŠ” 1 ì´ìƒì´ì–´ì•¼ í•©ë‹ˆë‹¤.")

    manifest_payload = json.loads(manifest_json.read_text(encoding="utf-8"))
    if not isinstance(manifest_payload, list):
        raise ValueError("manifest.json í˜•ì‹ì´ ì˜¬ë°”ë¥´ì§€ ì•ŠìŠµë‹ˆë‹¤(ë°°ì—´ì´ì–´ì•¼ í•¨).")

    image_paths: List[str] = []
    for item in sorted(
        (x for x in manifest_payload if isinstance(x, dict)),
        key=lambda x: (int(x.get("timestamp_ms", x.get("start_ms", 0))), str(x.get("file_name", ""))),
    ):
        file_name = str(item.get("file_name", "")).strip()
        if not file_name:
            continue
        image_paths.append(str(captures_dir / file_name))

    if not image_paths:
        raise ValueError("VLM ì…ë ¥ ì´ë¯¸ì§€ê°€ ì—†ìŠµë‹ˆë‹¤(manifest.jsonì„ í™•ì¸í•˜ì„¸ìš”).")

    results = extractor.extract_features(
        image_paths,
        batch_size=batch_size,
        show_progress=show_progress,
        concurrency=concurrency,
    )
    raw_path = extractor.get_output_path()
    write_vlm_raw_json(results, raw_path)

    convert_vlm_raw_to_fusion_vlm(
        manifest_json=manifest_json,
        vlm_raw_json=raw_path,
        output_vlm_json=raw_path.with_name("vlm.json"),
    )
    raw_path.unlink(missing_ok=True)
    
    return len(image_paths)


def _run_fusion_pipeline(
    config_path: Path, 
    *, 
    limit: Optional[int], 
    dry_run: bool,
    timer: BenchmarkTimer
) -> Dict[str, Any]:
    """
    Fusion íŒŒì´í”„ë¼ì¸ ì‹¤í–‰ (sync_engine â†’ LLM summarizer â†’ renderer â†’ final_summary).
    
    Returns:
        fusion ì„¸ë¶€ ë©”íŠ¸ë¦­ ë”•ì…”ë„ˆë¦¬
    """
    config = load_config(str(config_path))
    ensure_output_root(config.paths.output_root)

    fusion_info: Dict[str, Any] = {
        "segment_count": 0,
        "timings": {}
    }

    # Sync Engine
    _, sync_elapsed = timer.time_stage(
        "fusion.sync_engine",
        run_sync_engine,
        config,
        limit=limit,
        dry_run=False,
    )
    fusion_info["timings"]["sync_engine_sec"] = sync_elapsed

    # LLM Summarizer
    _, llm_elapsed = timer.time_stage(
        "fusion.llm_summarizer",
        run_summarizer,
        config,
        limit=limit,
        dry_run=dry_run,
    )
    fusion_info["timings"]["llm_summarizer_sec"] = llm_elapsed

    output_dir = config.paths.output_root / "fusion"
    
    if not dry_run:
        # Renderer
        _, render_elapsed = timer.time_stage(
            "fusion.renderer",
            render_segment_summaries_md,
            summaries_jsonl=output_dir / "segment_summaries.jsonl",
            output_md=output_dir / "segment_summaries.md",
            include_sources=config.raw.render.include_sources,
            sources_jsonl=output_dir / "segments_units.jsonl",
            md_wrap_width=config.raw.render.md_wrap_width,
            limit=limit,
        )
        fusion_info["timings"]["renderer_sec"] = render_elapsed

        # Final Summary
        summaries, final_elapsed = timer.time_stage(
            "fusion.final_summary",
            compose_final_summaries,
            summaries_jsonl=output_dir / "segment_summaries.jsonl",
            max_chars=config.raw.final_summary.max_chars_per_format,
            include_timestamps=config.raw.final_summary.style.include_timestamps,
            limit=limit,
        )
        fusion_info["timings"]["final_summary_sec"] = final_elapsed
        
        # ìµœì¢… ìš”ì•½ ì €ì¥
        outputs_dir = output_dir / "outputs"
        outputs_dir.mkdir(parents=True, exist_ok=True)
        for fmt in config.raw.final_summary.generate_formats:
            if fmt in summaries:
                outputs_dir.joinpath(f"final_summary_{fmt}.md").write_text(
                    summaries[fmt], encoding="utf-8"
                )
        
        # Judge ì‹¤í–‰
        judge_output_dir = output_dir / "judge"
        judge_output_dir.mkdir(parents=True, exist_ok=True)
        _, judge_elapsed = timer.time_stage(
            "fusion.judge",
            run_judge,
            config=config,
            segments_units_path=output_dir / "segments_units.jsonl",
            segment_summaries_path=output_dir / "segment_summaries.jsonl",
            output_report_path=judge_output_dir / "judge_report.json",
            output_segments_path=judge_output_dir / "judge_segment_reports.jsonl",
            batch_size=3,
            workers=1,
            json_repair_attempts=1,
            limit=limit,
            write_outputs=True,
            verbose=True,
            write_outputs=True,
        )
        fusion_info["timings"]["judge_sec"] = judge_elapsed
    
    # Segment ìˆ˜ ì¹´ìš´íŠ¸
    segments_file = output_dir / "segment_summaries.jsonl"
    if segments_file.exists():
        fusion_info["segment_count"] = sum(1 for _ in segments_file.open(encoding="utf-8"))
    
    return fusion_info


def _run_batch_fusion_pipeline(
    *,
    video_root: Path,
    captures_dir: Path,
    manifest_json: Path,
    stt_json: Path,
    video_name: str,
    batch_size: int,
    timer: BenchmarkTimer,
    vlm_batch_size: Optional[int],
    vlm_concurrency: int,
    vlm_show_progress: bool,
    limit: Optional[int],
    dry_run: bool,
    repo_root: Path,
) -> Dict[str, Any]:
    """
    ë°°ì¹˜ ëª¨ë“œ Fusion íŒŒì´í”„ë¼ì¸ ì‹¤í–‰.
    
    ìº¡ì²˜ë¥¼ batch_sizeì¥ì”© ë¶„í• í•˜ì—¬:
    VLM â†’ Sync â†’ Summarize â†’ Judge ë¥¼ ê° ë°°ì¹˜ë§ˆë‹¤ ë°˜ë³µ.
    
    Returns:
        fusion ì„¸ë¶€ ë©”íŠ¸ë¦­ ë”•ì…”ë„ˆë¦¬
    """
    import math
    from src.fusion.summarizer import run_batch_summarizer
    from src.judge.judge import run_judge
    
    # manifest ë¡œë“œ ë° ì •ë ¬
    manifest_payload = json.loads(manifest_json.read_text(encoding="utf-8"))
    sorted_manifest = sorted(
        (x for x in manifest_payload if isinstance(x, dict)),
        key=lambda x: (int(x.get("timestamp_ms", x.get("start_ms", 0))), str(x.get("file_name", ""))),
    )
    
    total_captures = len(sorted_manifest)
    total_batches = max(1, math.ceil(total_captures / batch_size))
    
    print(f"\nğŸ“¦ ë°°ì¹˜ ëª¨ë“œ: {total_captures}ì¥ì„ {total_batches}ê°œ ë°°ì¹˜ë¡œ ì²˜ë¦¬ (ë°°ì¹˜ë‹¹ {batch_size}ì¥)")
    
    # ë°°ì¹˜ ë²”ìœ„ ê³„ì‚°
    batch_ranges = []
    for i in range(total_batches):
        start_idx = i * batch_size
        end_idx = min((i + 1) * batch_size, total_captures)
        start_ms = int(sorted_manifest[start_idx].get("start_ms", sorted_manifest[start_idx].get("timestamp_ms", 0)))
        end_ms = int(sorted_manifest[end_idx - 1].get("end_ms", sorted_manifest[end_idx - 1].get("timestamp_ms", 0) + 1000))
        batch_ranges.append({
            "start_idx": start_idx,
            "end_idx": end_idx,
            "start_ms": start_ms,
            "end_ms": end_ms,
            "capture_count": end_idx - start_idx,
        })
    
    # ë°°ì¹˜ ë””ë ‰í† ë¦¬ ìƒì„±
    batches_dir = video_root / "batches"
    batches_dir.mkdir(parents=True, exist_ok=True)
    fusion_dir = video_root / "fusion"
    fusion_dir.mkdir(parents=True, exist_ok=True)
    
    # fusion config ìƒì„± (ì²« ë²ˆì§¸ ë°°ì¹˜ìš©)
    template_config = repo_root / "src" / "fusion" / "config.yaml"
    fusion_config_path = video_root / "config.yaml"
    
    fusion_info: Dict[str, Any] = {
        "segment_count": 0,
        "batch_count": total_batches,
        "batch_results": [],
        "timings": {},
    }
    
    cumulative_segment_count = 0
    previous_context = ""
    
    # ëˆ„ì  summaries íŒŒì¼ ì´ˆê¸°í™”
    accumulated_summaries_path = fusion_dir / "segment_summaries.jsonl"
    if accumulated_summaries_path.exists():
        accumulated_summaries_path.unlink()
    
    for batch_idx, batch_info in enumerate(batch_ranges):
        # ì²« ë°°ì¹˜ê°€ ì•„ë‹ˆë©´ API rate limiting ë°©ì§€ë¥¼ ìœ„í•´ ëŒ€ê¸°
        if batch_idx > 0:
            print(f"\nâ³ API rate limiting ë°©ì§€ë¥¼ ìœ„í•´ 5ì´ˆ ëŒ€ê¸°...")
            time.sleep(5)

        print(f"\n{'='*50}")
        print(f"ğŸ”„ ë°°ì¹˜ {batch_idx + 1}/{total_batches} ì²˜ë¦¬ ì¤‘...")
        print(f"   ìº¡ì²˜ ë²”ìœ„: {batch_info['start_idx']} ~ {batch_info['end_idx'] - 1}")
        print(f"{'='*50}")
        
        batch_dir = batches_dir / f"batch_{batch_idx}"
        batch_dir.mkdir(parents=True, exist_ok=True)
        
        # í•´ë‹¹ ë°°ì¹˜ì˜ ìº¡ì²˜ ëª©ë¡
        batch_manifest = sorted_manifest[batch_info["start_idx"]:batch_info["end_idx"]]
        
        # 1. VLM ì‹¤í–‰
        from src.adk_pipeline.tools.internal.vlm_openrouter import run_vlm_for_batch
        _, vlm_elapsed = timer.time_stage(
            f"batch_{batch_idx}.vlm",
            run_vlm_for_batch,
            captures_dir=captures_dir,
            manifest_json=manifest_json,
            video_name=video_name,
            output_dir=batch_dir,
            batch_manifest=batch_manifest,
            batch_size=vlm_batch_size,
            concurrency=vlm_concurrency,
            show_progress=vlm_show_progress,
        )
        
        # 2. Sync ì‹¤í–‰
        if not fusion_config_path.exists():
            _generate_fusion_config(
                template_config=template_config,
                output_config=fusion_config_path,
                repo_root=repo_root,
                stt_json=stt_json,
                vlm_json=batch_dir / "vlm.json",
                manifest_json=manifest_json,
                output_root=video_root,
            )
        
        from src.fusion.sync_engine import run_batch_sync_engine
        sync_result, sync_elapsed = timer.time_stage(
            f"batch_{batch_idx}.sync",
            run_batch_sync_engine,
            stt_json=stt_json,
            vlm_json=batch_dir / "vlm.json",
            manifest_json=manifest_json,
            output_dir=batch_dir,
            time_range=(batch_info["start_ms"], batch_info["end_ms"]),
            sync_config={
                "min_segment_sec": 15,
                "max_segment_sec": 120,
                "max_transcript_chars": 1000,
                "silence_gap_ms": 500,
                "max_visual_items": 10,
                "max_visual_chars": 3000,
                "dedup_similarity_threshold": 0.9,
            },
            segment_id_offset=cumulative_segment_count,
        )
        
        new_segment_count = sync_result.get("segments_count", 0)
        cumulative_segment_count += new_segment_count
        
        # 3. Summarize ì‹¤í–‰
        batch_segments_path = batch_dir / "segments_units.jsonl"
        batch_summaries_path = batch_dir / "segment_summaries.jsonl"
        
        if not dry_run:
            config = load_config(str(fusion_config_path))
            summarize_result, summarize_elapsed = timer.time_stage(
                f"batch_{batch_idx}.summarize",
                run_batch_summarizer,
                segments_units_jsonl=batch_segments_path,
                output_dir=batch_dir,
                config=config,
                previous_context=previous_context,
                limit=limit,
            )
            
            # context ì—…ë°ì´íŠ¸
            new_context = summarize_result.get("context", "")
            if new_context:
                previous_context = new_context[:500]
            
            # ëˆ„ì  ì €ì¥
            if batch_summaries_path.exists():
                with open(batch_summaries_path, "r", encoding="utf-8") as f:
                    batch_content = f.read()
                with open(accumulated_summaries_path, "a", encoding="utf-8") as f:
                    f.write(batch_content)
            
            # 4. Judge ì‹¤í–‰ (ì„ íƒì )
            batch_judge_path = batch_dir / "judge.json"
            config = load_config(str(fusion_config_path))
            _, judge_elapsed = timer.time_stage(
                f"batch_{batch_idx}.judge",
                run_judge,
                config=config,
                segments_units_path=batch_segments_path,
                segment_summaries_path=batch_summaries_path,
                output_report_path=batch_judge_path,
                output_segments_path=batch_dir / "judge_segments.jsonl",
                batch_size=3,
                workers=1,
                json_repair_attempts=1,
                limit=limit,
                verbose=False,
                write_outputs=True,
            )
            
            # Judge ê²°ê³¼ ì½ê¸°
            if batch_judge_path.exists():
                judge_result = json.loads(batch_judge_path.read_text(encoding="utf-8"))
                passed = judge_result.get("pass", True)
                score = judge_result.get("final_score", 0)
                print(f"  ğŸ“Š ë°°ì¹˜ {batch_idx} Judge: {'PASS' if passed else 'FAIL'} (score: {score:.1f})")
        
        fusion_info["batch_results"].append({
            "batch_index": batch_idx,
            "capture_range": [batch_info["start_idx"], batch_info["end_idx"]],
            "segments_count": new_segment_count,
        })
        
        print(f"  âœ… ë°°ì¹˜ {batch_idx + 1} ì™„ë£Œ! (ì„¸ê·¸ë¨¼íŠ¸: {new_segment_count}ê°œ)")
    
    fusion_info["segment_count"] = cumulative_segment_count
    
    # ìµœì¢… ë§ˆí¬ë‹¤ìš´ ë Œë”ë§
    if not dry_run and accumulated_summaries_path.exists():
        config = load_config(str(fusion_config_path))
        _, render_elapsed = timer.time_stage(
            "fusion.renderer",
            render_segment_summaries_md,
            summaries_jsonl=accumulated_summaries_path,
            output_md=fusion_dir / "segment_summaries.md",
            include_sources=config.raw.render.include_sources,
            sources_jsonl=fusion_dir / "segments_units.jsonl" if (fusion_dir / "segments_units.jsonl").exists() else None,
            md_wrap_width=config.raw.render.md_wrap_width,
            limit=limit,
        )
        fusion_info["timings"]["renderer_sec"] = render_elapsed
    
    return fusion_info
# ============================================================
# ë²¤ì¹˜ë§ˆí¬ ë¦¬í¬íŠ¸ ìƒì„±
# ============================================================

def _print_benchmark_report(
    video_info: Dict[str, Any],
    timer: BenchmarkTimer,
    capture_count: int,
    segment_count: int,
    video_path: Path,
    output_root: Path,
    parallel: bool
) -> str:
    """
    í„°ë¯¸ë„ì— ë²¤ì¹˜ë§ˆí¬ ê²°ê³¼ë¥¼ ì¶œë ¥í•˜ê³  ë§ˆí¬ë‹¤ìš´ ë¦¬í¬íŠ¸ ë°˜í™˜.
    """
    report = timer.get_report(video_info.get("duration_sec"))
    
    # í„°ë¯¸ë„ ì¶œë ¥
    print("\n" + "=" * 60)
    print("ğŸ“Š BENCHMARK REPORT")
    print("=" * 60)
    
    # ë¹„ë””ì˜¤ ì •ë³´
    print(f"\nğŸ“¹ Video: {video_path.name}")
    if video_info["duration_sec"]:
        print(f"   Duration: {_format_duration(video_info['duration_sec'])}")
    if video_info["width"] and video_info["height"]:
        print(f"   Resolution: {video_info['width']}x{video_info['height']}")
    if video_info["file_size_mb"]:
        print(f"   File Size: {video_info['file_size_mb']} MB")
    
    # ì²˜ë¦¬ í†µê³„
    print(f"\nğŸ“ˆ Processing Stats:")
    print(f"   Captures: {capture_count} frames")
    print(f"   Segments: {segment_count} segments")
    print(f"   Parallel Mode: {'Enabled' if parallel else 'Disabled'}")
    
    # íƒ€ì´ë° ê²°ê³¼
    print(f"\nâ±ï¸  Timing Breakdown:")
    print("-" * 50)
    
    # ì£¼ìš” ìŠ¤í…Œì´ì§€ ì •ë ¬ ì¶œë ¥
    stage_order = ["stt", "capture", "vlm", "fusion.sync_engine", "fusion.llm_summarizer", 
                   "fusion.renderer", "fusion.final_summary", "fusion.judge"]
    
    for stage in stage_order:
        if stage in report["stages"]:
            info = report["stages"][stage]
            bar_len = int(info["percentage"] / 2)
            bar = "â–ˆ" * bar_len + "â–‘" * (50 - bar_len)
            print(f"   {stage:24s} {info['elapsed_formatted']:>10s} ({info['percentage']:5.1f}%)")
    
    print("-" * 50)
    print(f"   {'TOTAL':24s} {report['total_elapsed_formatted']:>10s}")
    
    # ì†ë„ ë¹„ìœ¨
    if "speed_ratio" in report:
        print(f"\nğŸš€ Speed Ratio: {report['realtime_factor']} (video length)")
        if report["speed_ratio"] < 0.5:
            print("   âœ… ëª©í‘œ ë‹¬ì„±! (6ë¶„ ì˜ìƒ ê¸°ì¤€ 3ë¶„ ì´ë‚´)")
        else:
            print("   âš ï¸  ê²½ëŸ‰í™” í•„ìš” (ëª©í‘œ: 0.5x ì´í•˜)")
    
    print(f"\nğŸ“ Output: {output_root}")
    print("=" * 60 + "\n")
    
    # ë§ˆí¬ë‹¤ìš´ ë¦¬í¬íŠ¸ ìƒì„±
    md_lines = [
        "# Pipeline Benchmark Report",
        "",
        f"**Generated:** {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}",
        "",
        "## Video Information",
        "",
        f"- **File:** `{video_path.name}`",
    ]
    
    if video_info["duration_sec"]:
        md_lines.append(f"- **Duration:** {_format_duration(video_info['duration_sec'])}")
    if video_info["width"] and video_info["height"]:
        md_lines.append(f"- **Resolution:** {video_info['width']}x{video_info['height']}")
    if video_info["file_size_mb"]:
        md_lines.append(f"- **File Size:** {video_info['file_size_mb']} MB")
    
    md_lines.extend([
        "",
        "## Processing Statistics",
        "",
        f"- **Captured Frames:** {capture_count}",
        f"- **Segments Processed:** {segment_count}",
        f"- **Parallel Mode:** {'Enabled' if parallel else 'Disabled'}",
        "",
        "## Timing Breakdown",
        "",
        "| Stage | Time | Percentage |",
        "|-------|------|------------|",
    ])
    
    for stage in stage_order:
        if stage in report["stages"]:
            info = report["stages"][stage]
            md_lines.append(f"| {stage} | {info['elapsed_formatted']} | {info['percentage']:.1f}% |")
    
    md_lines.extend([
        f"| **TOTAL** | **{report['total_elapsed_formatted']}** | 100% |",
        "",
    ])
    
    if "speed_ratio" in report:
        md_lines.extend([
            "## Performance Analysis",
            "",
            f"- **Speed Ratio:** {report['realtime_factor']} of video duration",
            f"- **Status:** {'âœ… Target Achieved' if report['speed_ratio'] < 0.5 else 'âš ï¸ Optimization Required'}",
            "",
        ])
    
    return "\n".join(md_lines)


# ============================================================
# ë©”ì¸ í•¨ìˆ˜
# ============================================================

def parse_args() -> argparse.Namespace:
    """ì»¤ë§¨ë“œë¼ì¸ ì¸ì íŒŒì‹±."""
    parser = argparse.ArgumentParser(
        description="ë¹„ë””ì˜¤ íŒŒì´í”„ë¼ì¸ ë²¤ì¹˜ë§ˆí¬ (STT â†’ Capture â†’ VLM â†’ LLM)"
    )
    parser.add_argument("--video", required=True, help="ì…ë ¥ ë¹„ë””ì˜¤ íŒŒì¼ ê²½ë¡œ")
    parser.add_argument("--output-base", default="data/outputs", help="ì¶œë ¥ ë² ì´ìŠ¤ ë””ë ‰í† ë¦¬")
    parser.add_argument("--stt-backend", choices=["clova"], default="clova", help="STT ë°±ì—”ë“œ")
    parser.add_argument("--parallel", action=argparse.BooleanOptionalAction, default=True, help="STT+Capture ë³‘ë ¬ ì‹¤í–‰")
    parser.add_argument("--capture-threshold", type=float, default=3.0, help="ì¥ë©´ ì „í™˜ ê°ì§€ ì„ê³„ê°’")
    parser.add_argument("--capture-dedupe-threshold", type=float, default=3.0, help="ì¤‘ë³µ ì œê±° ì„ê³„ê°’ (2ì°¨ ì •ì œ)")
    parser.add_argument("--capture-min-interval", type=float, default=0.5, help="ìº¡ì²˜ ìµœì†Œ ê°„ê²©(ì´ˆ)")
    parser.add_argument("--capture-verbose", action="store_true", help="ìº¡ì²˜ ìƒì„¸ ë¡œê·¸ ì¶œë ¥")
    parser.add_argument("--vlm-batch-size", type=int, default=2, help="VLM ë°°ì¹˜ í¬ê¸°(ë¯¸ì§€ì • ì‹œ ì „ë¶€ í•œ ë²ˆì—)")
    parser.add_argument("--vlm-concurrency", type=int, default=3, help="VLM ë³‘ë ¬ ìš”ì²­ ìˆ˜ (ê¸°ë³¸: 3)")
    parser.add_argument("--vlm-show-progress", action=argparse.BooleanOptionalAction, default=True, help="VLM ì§„í–‰ ë¡œê·¸ ì¶œë ¥ ì—¬ë¶€ (ê¸°ë³¸: True)")
    parser.add_argument("--limit", type=int, default=None, help="fusion ë‹¨ê³„ì—ì„œ ì²˜ë¦¬í•  segment ìˆ˜ ì œí•œ")
    parser.add_argument("--dry-run", action="store_true", help="summarizer LLM ë¯¸í˜¸ì¶œ(ì¶œë ¥ ë¯¸ìƒì„±)")
    parser.add_argument("--batch-mode", action="store_true", default=False, help="ë°°ì¹˜ ëª¨ë“œ í™œì„±í™” (ìº¡ì²˜ë¥¼ nì¥ì”© ë¶„í•  ì²˜ë¦¬)")
    parser.add_argument("--batch-size", type=int, default=10, help="ë°°ì¹˜ë‹¹ ìº¡ì²˜ ê°œìˆ˜ (ê¸°ë³¸: 10)")
    return parser.parse_args()


def main() -> None:
    """ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜."""
    args = parse_args()

    video_path = Path(args.video).expanduser().resolve()
    if not video_path.exists():
        raise FileNotFoundError(f"ë¹„ë””ì˜¤ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {video_path}")

    repo_root = ROOT
    output_base = (repo_root / Path(args.output_base)).resolve()
    video_name = _sanitize_video_name(video_path.stem)
    video_root = output_base / video_name
    video_root.mkdir(parents=True, exist_ok=True)
    
    # ë²¤ì¹˜ë§ˆí¬ íƒ€ì´ë¨¸ ì´ˆê¸°í™”
    timer = BenchmarkTimer()
    
    # ë¹„ë””ì˜¤ ì •ë³´ ì¶”ì¶œ
    print(f"\nğŸ¬ Analyzing video: {video_path.name}")
    video_info = _get_video_info(video_path)
    if video_info["duration_sec"]:
        print(f"   Duration: {_format_duration(video_info['duration_sec'])}")

    # ë©”íƒ€ë°ì´í„° ì´ˆê¸°í™”
    run_meta_path = video_root / "pipeline_run.json"
    run_meta: Dict[str, Any] = {
        "schema_version": 2,
        "video_path": str(video_path),
        "video_name": video_name,
        "video_info": video_info,
        "output_base": str(output_base),
        "video_root": str(video_root),
        "started_at_utc": _utc_now_iso(),
        "args": vars(args),
        "durations_sec": {},
        "benchmark": {},
        "status": "running",
    }
    _write_json(run_meta_path, run_meta)

    timer.start_total()
    capture_count = 0
    segment_count = 0
    
    try:
        stt_json = video_root / "stt.json"
        captures_dir = video_root / "captures"
        manifest_json = video_root / "manifest.json"

        print(f"\nğŸš€ Starting pipeline (parallel={args.parallel})...")
        print("-" * 50)

        stt_elapsed = 0.0
        capture_elapsed = 0.0

        if args.parallel:
            # ë³‘ë ¬ ì‹¤í–‰
            with ThreadPoolExecutor(max_workers=2) as executor:
                def run_stt_timed():
                    start = time.perf_counter()
                    _run_stt(video_path, stt_json, backend=args.stt_backend)
                    return time.perf_counter() - start
                
                def run_capture_timed():
                    start = time.perf_counter()
                    result = _run_capture(
                        video_path, output_base,
                        threshold=args.capture_threshold,
                        dedupe_threshold=args.capture_dedupe_threshold,
                        min_interval=args.capture_min_interval,
                        verbose=args.capture_verbose,
                        video_name=video_name,
                    )
                    elapsed = time.perf_counter() - start
                    return result, elapsed
                
                stt_future = executor.submit(run_stt_timed)
                capture_future = executor.submit(run_capture_timed)
                
                stt_elapsed = stt_future.result()
                capture_result, capture_elapsed = capture_future.result()
                capture_count = len(capture_result) if capture_result else 0
            
            # ë³‘ë ¬ ì‹¤í–‰ ê²°ê³¼ ê¸°ë¡
            timer.record_stage("stt", stt_elapsed)
            timer.record_stage("capture", capture_elapsed)
            print(f"  âœ“ stt: {_format_duration(stt_elapsed)} (parallel)")
            print(f"  âœ“ capture: {_format_duration(capture_elapsed)} (parallel)")
        else:
            # ìˆœì°¨ ì‹¤í–‰
            _, stt_elapsed = timer.time_stage(
                "stt", _run_stt, video_path, stt_json, backend=args.stt_backend
            )
            capture_result, capture_elapsed = timer.time_stage(
                "capture", _run_capture, video_path, output_base,
                threshold=args.capture_threshold,
                dedupe_threshold=args.capture_dedupe_threshold,
                min_interval=args.capture_min_interval,
                verbose=args.capture_verbose,
                video_name=video_name,
            )
            capture_count = len(capture_result) if capture_result else 0

<<<<<<< HEAD
        # VLM ì‹¤í–‰
        vlm_image_count, vlm_elapsed = timer.time_stage(
            "vlm",
            _run_vlm_openrouter,
            captures_dir=captures_dir,
            manifest_json=manifest_json,
            video_name=video_name,
            output_base=output_base,
            batch_size=args.vlm_batch_size,
            concurrency=args.vlm_concurrency,
            show_progress=args.vlm_show_progress,
        )

        # Fusion config ìƒì„±
        template_config = repo_root / "src" / "fusion" / "config.yaml"
        if not template_config.exists():
            raise FileNotFoundError(f"fusion config templateì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {template_config}")
        
        fusion_config_path = video_root / "config.yaml"
        _generate_fusion_config(
            template_config=template_config,
            output_config=fusion_config_path,
            repo_root=repo_root,
            stt_json=stt_json,
            vlm_json=video_root / "vlm.json",
            manifest_json=manifest_json,
=======
        # ë°°ì¹˜ ëª¨ë“œ vs ì¼ë°˜ ëª¨ë“œ ë¶„ê¸°
        if args.batch_mode:
            # ë°°ì¹˜ ëª¨ë“œ: VLM â†’ Sync â†’ Summarize â†’ Judgeë¥¼ ë°°ì¹˜ ë‹¨ìœ„ë¡œ ë°˜ë³µ
            vlm_elapsed = 0.0  # ë°°ì¹˜ì—ì„œ ë‚´ë¶€ì ìœ¼ë¡œ ì¸¡ì •
            fusion_info = _run_batch_fusion_pipeline(
                video_root=video_root,
                captures_dir=captures_dir,
                manifest_json=manifest_json,
                stt_json=stt_json,
                video_name=video_name,
                batch_size=args.batch_size,
                timer=timer,
                vlm_batch_size=args.vlm_batch_size,
                vlm_concurrency=args.vlm_concurrency,
                vlm_show_progress=args.vlm_show_progress,
                limit=args.limit,
                dry_run=args.dry_run,
                repo_root=repo_root,
            )
            segment_count = fusion_info.get("segment_count", 0)
            vlm_image_count = capture_count  # ë°°ì¹˜ ëª¨ë“œì—ì„œëŠ” ìº¡ì²˜ ìˆ˜ì™€ ë™ì¼
        else:
            # ì¼ë°˜ ëª¨ë“œ: VLM ì „ì²´ ì‹¤í–‰ í›„ Fusion íŒŒì´í”„ë¼ì¸
            vlm_image_count, vlm_elapsed = timer.time_stage(
                "vlm",
                _run_vlm_openrouter,
                captures_dir=captures_dir,
                manifest_json=manifest_json,
                video_name=video_name,
                output_base=output_base,
                batch_size=args.vlm_batch_size,
                concurrency=args.vlm_concurrency,
                show_progress=args.vlm_show_progress,
            )

            # Fusion config ìƒì„±
            template_config = repo_root / "src" / "fusion" / "config.yaml"
            if not template_config.exists():
                raise FileNotFoundError(f"fusion config templateì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {template_config}")
            
            fusion_config_path = video_root / "config.yaml"
            _generate_fusion_config(
                template_config=template_config,
                output_config=fusion_config_path,
                repo_root=repo_root,
                stt_json=stt_json,
                vlm_json=video_root / "vlm.json",
                manifest_json=manifest_json,
                output_root=video_root,
            )

            # Fusion íŒŒì´í”„ë¼ì¸ ì‹¤í–‰
            fusion_info = _run_fusion_pipeline(
                fusion_config_path, 
                limit=args.limit, 
                dry_run=args.dry_run,
                timer=timer
            )
            segment_count = fusion_info.get("segment_count", 0)
        
        timer.end_total()

        # ë²¤ì¹˜ë§ˆí¬ ë¦¬í¬íŠ¸ ìƒì„± ë° ì¶œë ¥
        md_report = _print_benchmark_report(
            video_info=video_info,
            timer=timer,
            capture_count=capture_count,
            segment_count=segment_count,
            video_path=video_path,
>>>>>>> feat
            output_root=video_root,
            parallel=args.parallel
        )
        
        # ë§ˆí¬ë‹¤ìš´ ë¦¬í¬íŠ¸ ì €ì¥
        report_path = video_root / "benchmark_report.md"
        report_path.write_text(md_report, encoding="utf-8")

<<<<<<< HEAD
        # Fusion íŒŒì´í”„ë¼ì¸ ì‹¤í–‰
        fusion_info = _run_fusion_pipeline(
            fusion_config_path, 
            limit=args.limit, 
            dry_run=args.dry_run,
            timer=timer
        )
        segment_count = fusion_info.get("segment_count", 0)
        
        timer.end_total()

        # ë²¤ì¹˜ë§ˆí¬ ë¦¬í¬íŠ¸ ìƒì„± ë° ì¶œë ¥
        md_report = _print_benchmark_report(
            video_info=video_info,
            timer=timer,
            capture_count=capture_count,
            segment_count=segment_count,
            video_path=video_path,
            output_root=video_root,
            parallel=args.parallel
        )
        
        # ë§ˆí¬ë‹¤ìš´ ë¦¬í¬íŠ¸ ì €ì¥
        report_path = video_root / "benchmark_report.md"
        report_path.write_text(md_report, encoding="utf-8")

=======
>>>>>>> feat
        # ìµœì¢… ë©”íƒ€ë°ì´í„° ì €ì¥
        benchmark_report = timer.get_report(video_info.get("duration_sec"))
        
        run_meta["durations_sec"] = {
            "stt_sec": round(stt_elapsed, 6),
            "capture_sec": round(capture_elapsed, 6),
            "vlm_sec": round(vlm_elapsed, 6),
            "total_sec": round(timer.get_total_elapsed(), 6),
            **{f"fusion.{k}": round(v, 6) for k, v in fusion_info.get("timings", {}).items()},
        }
        run_meta["benchmark"] = benchmark_report
        run_meta["processing_stats"] = {
            "capture_count": capture_count,
            "vlm_image_count": vlm_image_count,
            "segment_count": segment_count,
        }
        run_meta["ended_at_utc"] = _utc_now_iso()
        run_meta["status"] = "ok"
        _write_json(run_meta_path, run_meta)

        print(f"âœ… Pipeline completed successfully!")
        print(f"   Outputs: {video_root}")
        print(f"   Benchmark: {report_path}")
        
    except Exception as exc:
        timer.end_total()
        run_meta["ended_at_utc"] = _utc_now_iso()
        run_meta["status"] = "error"
        run_meta["error"] = str(exc)
        run_meta["durations_sec"]["total_sec"] = round(timer.get_total_elapsed(), 6)
        _write_json(run_meta_path, run_meta)
        print(f"\nâŒ Pipeline failed: {exc}")
        raise


if __name__ == "__main__":
    main()
