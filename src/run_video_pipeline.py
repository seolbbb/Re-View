"""
ÎπÑÎîîÏò§ ÌååÏù¥ÌîÑÎùºÏù∏ Î™ÖÎ†πÏ§Ñ ÏßÑÏûÖÏ†ê.

STT ‚Üí Capture ‚Üí VLM ‚Üí Fusion Ï†Ñ Í≥ºÏ†ïÏùÑ Ïã§ÌñâÌïòÍ≥† Î≤§ÏπòÎßàÌÅ¨ Î¶¨Ìè¨Ìä∏Î•º ÎÇ®Í∏¥Îã§.
"""

from __future__ import annotations

import argparse
import json
import re
import sys
import time
from concurrent.futures import ThreadPoolExecutor
from datetime import datetime, timezone
from pathlib import Path
from typing import Any, Dict, Optional

from dotenv import load_dotenv

ROOT = Path(__file__).resolve().parents[1]
if str(ROOT) not in sys.path:
    sys.path.append(str(ROOT))

ENV_PATH = ROOT / ".env"
if ENV_PATH.exists():
    load_dotenv(ENV_PATH)
else:
    load_dotenv()

from src.db import sync_pipeline_results_to_db
from src.pipeline.benchmark import (
    BenchmarkTimer,
    format_duration,
    get_video_info,
    print_benchmark_report,
)
from src.pipeline.stages import (
    generate_fusion_config,
    run_batch_fusion_pipeline,
    run_capture,
    run_fusion_pipeline,
    run_stt,
    run_vlm_openrouter,
)


def _sanitize_video_name(stem: str) -> str:
    """ÎπÑÎîîÏò§ Ïù¥Î¶ÑÏùÑ ÏïàÏ†ÑÌïú ÎîîÎ†âÌÜ†Î¶¨ Ïù¥Î¶ÑÏúºÎ°ú Ï†ïÍ∑úÌôîÌïúÎã§."""
    value = stem.strip()
    value = re.sub(r"\s+", "_", value)
    value = re.sub(r"[^A-Za-z0-9Í∞Ä-Ìû£._-]+", "_", value)
    value = re.sub(r"_+", "_", value).strip("._-")
    if not value:
        return "video"
    return value[:80]


def _write_json(path: Path, payload: Any) -> None:
    """JSON ÌååÏùºÏùÑ UTF-8Î°ú Ï†ÄÏû•ÌïúÎã§."""
    path.parent.mkdir(parents=True, exist_ok=True)
    with path.open("w", encoding="utf-8") as handle:
        json.dump(payload, handle, ensure_ascii=False, indent=2, sort_keys=True)


def parse_args() -> argparse.Namespace:
    """Î™ÖÎ†πÏ§Ñ Ïù∏ÏûêÎ•º ÌååÏã±ÌïúÎã§."""
    parser = argparse.ArgumentParser(
        description="ÎπÑÎîîÏò§ ÌååÏù¥ÌîÑÎùºÏù∏ Î≤§ÏπòÎßàÌÅ¨ (STT ‚Üí Capture ‚Üí VLM ‚Üí LLM)"
    )
    parser.add_argument("--video", required=True, help="ÏûÖÎ†• ÎπÑÎîîÏò§ ÌååÏùº Í≤ΩÎ°ú")
    parser.add_argument("--output-base", default="data/outputs", help="Ï∂úÎ†• Î≤†Ïù¥Ïä§ ÎîîÎ†âÌÜ†Î¶¨")
    parser.add_argument("--stt-backend", choices=["clova"], default="clova", help="STT Î∞±ÏóîÎìú")
    parser.add_argument(
        "--parallel", action=argparse.BooleanOptionalAction, default=True, help="STT+Capture Î≥ëÎ†¨ Ïã§Ìñâ"
    )
    parser.add_argument("--capture-threshold", type=float, default=3.0, help="Ïû•Î©¥ Ï†ÑÌôò Í∞êÏßÄ ÏûÑÍ≥ÑÍ∞í")
    parser.add_argument(
        "--capture-dedupe-threshold", type=float, default=3.0, help="Ï§ëÎ≥µ Ï†úÍ±∞ ÏûÑÍ≥ÑÍ∞í (2Ï∞® Ï†ïÏ†ú)"
    )
    parser.add_argument("--capture-min-interval", type=float, default=0.5, help="Ï∫°Ï≤ò ÏµúÏÜå Í∞ÑÍ≤©(Ï¥à)")
    parser.add_argument("--capture-verbose", action="store_true", help="Ï∫°Ï≤ò ÏÉÅÏÑ∏ Î°úÍ∑∏ Ï∂úÎ†•")
    parser.add_argument("--vlm-batch-size", type=int, default=2, help="VLM Î∞∞Ïπò ÌÅ¨Í∏∞(ÎØ∏ÏßÄÏ†ï Ïãú Ï†ÑÎ∂Ä Ìïú Î≤àÏóê)")
    parser.add_argument("--vlm-concurrency", type=int, default=3, help="VLM Î≥ëÎ†¨ ÏöîÏ≤≠ Ïàò (Í∏∞Î≥∏: 3)")
    parser.add_argument(
        "--vlm-show-progress",
        action=argparse.BooleanOptionalAction,
        default=True,
        help="VLM ÏßÑÌñâ Î°úÍ∑∏ Ï∂úÎ†• Ïó¨Î∂Ä (Í∏∞Î≥∏: True)",
    )
    parser.add_argument("--limit", type=int, default=None, help="fusion Îã®Í≥ÑÏóêÏÑú Ï≤òÎ¶¨Ìï† segment Ïàò Ï†úÌïú")
    parser.add_argument("--dry-run", action="store_true", help="summarizer LLM ÎØ∏Ìò∏Ï∂ú(Ï∂úÎ†• ÎØ∏ÏÉùÏÑ±)")
    parser.add_argument(
        "--batch-mode", action="store_true", default=False, help="Î∞∞Ïπò Î™®Îìú ÌôúÏÑ±Ìôî (Ï∫°Ï≤òÎ•º nÏû•Ïî© Î∂ÑÌï† Ï≤òÎ¶¨)"
    )
    parser.add_argument("--batch-size", type=int, default=10, help="Î∞∞ÏπòÎãπ Ï∫°Ï≤ò Í∞úÏàò (Í∏∞Î≥∏: 10)")
    return parser.parse_args()


def run_pipeline(
    *,
    video: str,
    output_base: str,
    stt_backend: str,
    parallel: bool,
    capture_threshold: float,
    capture_dedupe_threshold: float,
    capture_min_interval: float,
    capture_verbose: bool,
    vlm_batch_size: Optional[int],
    vlm_concurrency: int,
    vlm_show_progress: bool,
    limit: Optional[int],
    dry_run: bool,
    batch_mode: bool,
    batch_size: int,
) -> None:
    """ÎπÑÎîîÏò§ 1Í±¥ÏùÑ end-to-endÎ°ú Ï≤òÎ¶¨ÌïòÍ≥† Í≤∞Í≥º/Î©îÌä∏Î¶≠ÏùÑ Í∏∞Î°ùÌïúÎã§.

    Îã®Í≥Ñ: STT ‚Üí Capture ‚Üí VLM ‚Üí Fusion ‚Üí (ÏòµÏÖò) Judge.
    ÏÇ∞Ï∂úÎ¨º: Ï∂úÎ†• Ìè¥ÎçîÏóê stt/vlm/manifest/fusion Í≤∞Í≥ºÏôÄ Î≤§ÏπòÎßàÌÅ¨ Î¶¨Ìè¨Ìä∏ ÏÉùÏÑ±.
    ÏΩîÎìú ÏúÑÏπò: STT(run_stt), Capture(run_capture), VLM(run_vlm_openrouter),
    Fusion(generate_fusion_config + run_fusion_pipeline) ÎòêÎäî Î∞∞Ïπò Î™®Îìú(run_batch_fusion_pipeline).
    """
    video_path = Path(video).expanduser().resolve()
    if not video_path.exists():
        raise FileNotFoundError(f"ÎπÑÎîîÏò§ ÌååÏùºÏùÑ Ï∞æÏùÑ Ïàò ÏóÜÏäµÎãàÎã§: {video_path}")

    repo_root = ROOT
    output_base_path = (repo_root / Path(output_base)).resolve()
    video_name = _sanitize_video_name(video_path.stem)
    video_root = output_base_path / video_name
    video_root.mkdir(parents=True, exist_ok=True)

    timer = BenchmarkTimer()

    print(f"\nüé¨ Analyzing video: {video_path.name}")
    video_info = get_video_info(video_path)
    if video_info["duration_sec"]:
        print(f"   Duration: {format_duration(video_info['duration_sec'])}")

    run_meta_path = video_root / "pipeline_run.json"
    run_args = {
        "video": str(video_path),
        "output_base": str(output_base_path),
        "stt_backend": stt_backend,
        "parallel": parallel,
        "capture_threshold": capture_threshold,
        "capture_dedupe_threshold": capture_dedupe_threshold,
        "capture_min_interval": capture_min_interval,
        "capture_verbose": capture_verbose,
        "vlm_batch_size": vlm_batch_size,
        "vlm_concurrency": vlm_concurrency,
        "vlm_show_progress": vlm_show_progress,
        "limit": limit,
        "dry_run": dry_run,
        "batch_mode": batch_mode,
        "batch_size": batch_size,
    }
    run_meta: Dict[str, Any] = {
        "video_path": str(video_path),
        "video_name": video_name,
        "video_info": video_info,
        "output_base": str(output_base_path),
        "video_root": str(video_root),
        "started_at_utc": datetime.now(timezone.utc).isoformat(),
        "args": run_args,
        "durations_sec": {},
        "benchmark": {},
        "status": "running",
    }
    _write_json(run_meta_path, run_meta)

    timer.start_total()
    capture_count = 0
    segment_count = 0

    try:
        """STT/Capture ÏûÖÎ†•/Ï∂úÎ†• Í≤ΩÎ°ú Ï§ÄÎπÑ."""
        stt_json = video_root / "stt.json"
        captures_dir = video_root / "captures"
        manifest_json = video_root / "manifest.json"

        print(f"\nüöÄ Starting pipeline (parallel={parallel})...")
        print("-" * 50)

        stt_elapsed = 0.0
        capture_elapsed = 0.0

        """STT + Capture Ïã§Ìñâ."""
        if parallel:
            with ThreadPoolExecutor(max_workers=2) as executor:
                def run_stt_timed():
                    """STT Îã®Í≥ÑÎ•º ÌÉÄÏù¥Î∞ç Ìè¨Ìï®ÏúºÎ°ú Ïã§ÌñâÌïúÎã§."""
                    start = time.perf_counter()
                    run_stt(video_path, stt_json, backend=stt_backend)
                    return time.perf_counter() - start

                def run_capture_timed():
                    """Capture Îã®Í≥ÑÎ•º ÌÉÄÏù¥Î∞ç Ìè¨Ìï®ÏúºÎ°ú Ïã§ÌñâÌïúÎã§."""
                    start = time.perf_counter()
                    result = run_capture(
                        video_path,
                        output_base_path,
                        threshold=capture_threshold,
                        dedupe_threshold=capture_dedupe_threshold,
                        min_interval=capture_min_interval,
                        verbose=capture_verbose,
                        video_name=video_name,
                    )
                    elapsed = time.perf_counter() - start
                    return result, elapsed

                stt_future = executor.submit(run_stt_timed)
                capture_future = executor.submit(run_capture_timed)

                stt_elapsed = stt_future.result()
                capture_result, capture_elapsed = capture_future.result()
                capture_count = len(capture_result) if capture_result else 0

            timer.record_stage("stt", stt_elapsed)
            timer.record_stage("capture", capture_elapsed)
            print(f"  ‚úì STT done in {format_duration(stt_elapsed)} (parallel)")
            print(f"  ‚úì Capture done in {format_duration(capture_elapsed)} (parallel)")
        else:
            """STT + Capture ÏàúÏ∞® Ïã§Ìñâ."""
            _, stt_elapsed = timer.time_stage("STT", run_stt, video_path, stt_json, backend=stt_backend)
            capture_result, capture_elapsed = timer.time_stage(
                "Capture",
                run_capture,
                video_path,
                output_base_path,
                threshold=capture_threshold,
                dedupe_threshold=capture_dedupe_threshold,
                min_interval=capture_min_interval,
                verbose=capture_verbose,
                video_name=video_name,
            )
            capture_count = len(capture_result) if capture_result else 0

        """VLM + Fusion Ïã§Ìñâ."""
        if batch_mode:
            """Î∞∞Ïπò Î™®Îìú: VLM/Sync/SummarizeÎ•º Î∞∞Ïπò Îã®ÏúÑÎ°ú Î∞òÎ≥µ."""
            vlm_elapsed = 0.0
            fusion_info = run_batch_fusion_pipeline(
                video_root=video_root,
                captures_dir=captures_dir,
                manifest_json=manifest_json,
                stt_json=stt_json,
                video_name=video_name,
                batch_size=batch_size,
                timer=timer,
                vlm_batch_size=vlm_batch_size,
                vlm_concurrency=vlm_concurrency,
                vlm_show_progress=vlm_show_progress,
                limit=limit,
                dry_run=dry_run,
                repo_root=repo_root,
            )
            segment_count = fusion_info.get("segment_count", 0)
            vlm_image_count = capture_count
        else:
            """VLM Îã®ÎèÖ Ïã§Ìñâ."""
            vlm_image_count, vlm_elapsed = timer.time_stage(
                "VLM",
                run_vlm_openrouter,
                captures_dir=captures_dir,
                manifest_json=manifest_json,
                video_name=video_name,
                output_base=output_base_path,
                batch_size=vlm_batch_size,
                concurrency=vlm_concurrency,
                show_progress=vlm_show_progress,
            )

            template_config = repo_root / "config" / "fusion" / "config.yaml"
            if not template_config.exists():
                raise FileNotFoundError(f"fusion config templateÏùÑ Ï∞æÏùÑ Ïàò ÏóÜÏäµÎãàÎã§: {template_config}")

            fusion_config_path = video_root / "config.yaml"
            """Fusion ÏÑ§Ï†ï ÏÉùÏÑ±."""
            generate_fusion_config(
                template_config=template_config,
                output_config=fusion_config_path,
                repo_root=repo_root,
                stt_json=stt_json,
                vlm_json=video_root / "vlm.json",
                manifest_json=manifest_json,
                output_root=video_root,
            )

            """Fusion ÌååÏù¥ÌîÑÎùºÏù∏ Ïã§Ìñâ."""
            fusion_info = run_fusion_pipeline(
                fusion_config_path,
                limit=limit,
                dry_run=dry_run,
                timer=timer,
            )
            segment_count = fusion_info.get("segment_count", 0)

        timer.end_total()

        md_report = print_benchmark_report(
            video_info=video_info,
            timer=timer,
            capture_count=capture_count,
            segment_count=segment_count,
            video_path=video_path,
            output_root=video_root,
            parallel=parallel,
        )

        report_path = video_root / "benchmark_report.md"
        report_path.write_text(md_report, encoding="utf-8")

        benchmark_report = timer.get_report(video_info.get("duration_sec"))

        run_meta["durations_sec"] = {
            "stt_sec": round(stt_elapsed, 6),
            "capture_sec": round(capture_elapsed, 6),
            "vlm_sec": round(vlm_elapsed, 6),
            "total_sec": round(timer.get_total_elapsed(), 6),
            **{f"fusion.{k}": round(v, 6) for k, v in fusion_info.get("timings", {}).items()},
        }
        run_meta["benchmark"] = benchmark_report
        run_meta["processing_stats"] = {
            "capture_count": capture_count,
            "vlm_image_count": vlm_image_count,
            "segment_count": segment_count,
        }
        run_meta["ended_at_utc"] = datetime.now(timezone.utc).isoformat()
        run_meta["status"] = "ok"
        _write_json(run_meta_path, run_meta)

        print("\n‚úÖ Pipeline completed successfully!")
        print(f"   Outputs: {video_root}")
        print(f"   Benchmark: {report_path}")

        print("\nüì§ Syncing results to Supabase...")
        db_success = sync_pipeline_results_to_db(
            video_path=video_path,
            video_root=video_root,
            run_meta=run_meta,
            duration_sec=video_info.get("duration_sec"),
            provider=stt_backend,
        )
        if db_success:
            print("‚úÖ Database sync completed!")
        else:
            print("‚ö†Ô∏è Database sync skipped or failed (check logs above)")

    except Exception as exc:
        timer.end_total()
        run_meta["ended_at_utc"] = datetime.now(timezone.utc).isoformat()
        run_meta["status"] = "error"
        run_meta["error"] = str(exc)
        run_meta["durations_sec"]["total_sec"] = round(timer.get_total_elapsed(), 6)
        _write_json(run_meta_path, run_meta)
        print(f"\n‚ùå Pipeline failed: {exc}")
        raise


def main() -> None:
    """CLI ÏßÑÏûÖÏ†ê."""
    args = parse_args()
    run_pipeline(
        video=args.video,
        output_base=args.output_base,
        stt_backend=args.stt_backend,
        parallel=args.parallel,
        capture_threshold=args.capture_threshold,
        capture_dedupe_threshold=args.capture_dedupe_threshold,
        capture_min_interval=args.capture_min_interval,
        capture_verbose=args.capture_verbose,
        vlm_batch_size=args.vlm_batch_size,
        vlm_concurrency=args.vlm_concurrency,
        vlm_show_progress=args.vlm_show_progress,
        limit=args.limit,
        dry_run=args.dry_run,
        batch_mode=args.batch_mode,
        batch_size=args.batch_size,
    )


if __name__ == "__main__":
    main()
